{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPBkFvYqbyV8p6Wa8uyD5PS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**# SETUP AND DEPENDENCIES**"],"metadata":{"id":"vZjeEZo2VjI3"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Prt1qCVUVcYg"},"outputs":[],"source":["# Install required packages\n","!pip install -q neo4j pandas numpy matplotlib networkx sentence-transformers scikit-learn faiss-cpu\n","\n","import json\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import networkx as nx\n","from typing import List, Dict, Any, Tuple\n","from collections import defaultdict, deque\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","try:\n","    from sentence_transformers import SentenceTransformer\n","    import faiss\n","    from sklearn.metrics.pairwise import cosine_similarity\n","    print(\"‚úÖ All packages loaded successfully\")\n","except ImportError as e:\n","    print(f\"‚ö†Ô∏è Some packages may not be available: {e}\")\n","\n","print(\"üöÄ Setup complete! Ready for graph-enhanced retrieval.\")"]},{"cell_type":"markdown","source":["**# LOAD KNOWLEDGE GRAPH DATA**"],"metadata":{"id":"OcXu10gFWT2w"}},{"cell_type":"code","source":["def load_sample_knowledge_graph():\n","    \"\"\"Load or create sample knowledge graph data.\"\"\"\n","    try:\n","        with open('processed_knowledge_for_graph.json', 'r') as f:\n","            data = json.load(f)\n","        print(\"‚úÖ Loaded knowledge graph from previous notebook\")\n","        return data\n","    except FileNotFoundError:\n","        print(\"‚ö†Ô∏è Creating sample data for demonstration...\")\n","        return create_sample_graph_data()\n","\n","def create_sample_graph_data():\n","    \"\"\"Create sample knowledge graph data.\"\"\"\n","    sample_data = {\n","        'entities': {\n","            'concept_0': {'id': 'concept_0', 'text': 'Transformer', 'type': 'CONCEPT'},\n","            'concept_1': {'id': 'concept_1', 'text': 'attention mechanisms', 'type': 'CONCEPT'},\n","            'concept_2': {'id': 'concept_2', 'text': 'BERT', 'type': 'CONCEPT'},\n","            'concept_3': {'id': 'concept_3', 'text': 'machine translation', 'type': 'CONCEPT'},\n","            'person_0': {'id': 'person_0', 'text': 'Ashish Vaswani', 'type': 'PERSON'},\n","            'person_1': {'id': 'person_1', 'text': 'Jacob Devlin', 'type': 'PERSON'},\n","            'metric_0': {'id': 'metric_0', 'text': 'BLEU', 'type': 'METRIC'},\n","            'dataset_0': {'id': 'dataset_0', 'text': 'WMT 2014', 'type': 'DATASET'}\n","        },\n","        'relationships': [\n","            {'source': 'concept_0', 'target': 'concept_1', 'type': 'BASED_ON', 'confidence': 0.9},\n","            {'source': 'concept_2', 'target': 'concept_0', 'type': 'BASED_ON', 'confidence': 0.85},\n","            {'source': 'concept_0', 'target': 'concept_3', 'type': 'EVALUATES_ON', 'confidence': 0.8},\n","            {'source': 'concept_0', 'target': 'metric_0', 'type': 'ACHIEVES', 'confidence': 0.9},\n","            {'source': 'person_0', 'target': 'concept_0', 'type': 'INTRODUCED', 'confidence': 1.0},\n","            {'source': 'person_1', 'target': 'concept_2', 'type': 'INTRODUCED', 'confidence': 1.0}\n","        ],\n","        'documents': {\n","            'paper_1': {\n","                'id': 'paper_1',\n","                'title': 'Attention Is All You Need',\n","                'content': 'We propose a new simple network architecture, the Transformer, based solely on attention mechanisms...',\n","                'entities': ['concept_0', 'concept_1', 'person_0', 'metric_0']\n","            },\n","            'paper_2': {\n","                'id': 'paper_2',\n","                'title': 'BERT: Pre-training of Deep Bidirectional Transformers',\n","                'content': 'We introduce BERT, which stands for Bidirectional Encoder Representations from Transformers...',\n","                'entities': ['concept_2', 'concept_0', 'person_1']\n","            }\n","        }\n","    }\n","    return sample_data\n","\n","# Load the knowledge graph data\n","kg_data = load_sample_knowledge_graph()\n","print(f\"üìä Knowledge Graph: {len(kg_data.get('entities', {}))} entities, {len(kg_data.get('relationships', []))} relationships\")\n"],"metadata":{"id":"1vVSGmmKWT__"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**# PART 1: GRAPH TRAVERSAL RETRIEVER**"],"metadata":{"id":"8Bmt34RfWc3U"}},{"cell_type":"code","source":["class GraphTraversalRetriever:\n","    \"\"\"Implement graph traversal techniques for information retrieval.\"\"\"\n","\n","    def __init__(self, kg_data: Dict):\n","        self.kg_data = kg_data\n","        self.entities = kg_data.get('entities', {})\n","        self.relationships = kg_data.get('relationships', [])\n","        self.build_graph_structure()\n","\n","    def build_graph_structure(self):\n","        \"\"\"Build internal graph representation for traversal.\"\"\"\n","        self.adjacency_list = defaultdict(list)\n","        self.reverse_adjacency = defaultdict(list)\n","\n","        for rel in self.relationships:\n","            source = rel['source']\n","            target = rel['target']\n","            rel_type = rel['type']\n","            confidence = rel.get('confidence', 0.5)\n","\n","            # Forward edges\n","            self.adjacency_list[source].append({\n","                'target': target,\n","                'relationship': rel_type,\n","                'confidence': confidence\n","            })\n","\n","            # Reverse edges for bidirectional traversal\n","            self.reverse_adjacency[target].append({\n","                'source': source,\n","                'relationship': rel_type,\n","                'confidence': confidence\n","            })\n","\n","    def find_entity_by_text(self, text: str, threshold: float = 0.8) -> List[str]:\n","        \"\"\"Find entities matching the given text.\"\"\"\n","        matches = []\n","        text_lower = text.lower()\n","\n","        for entity_id, entity_data in self.entities.items():\n","            entity_text = entity_data['text'].lower()\n","\n","            if text_lower == entity_text:\n","                matches.append((entity_id, 1.0))\n","            elif text_lower in entity_text or entity_text in text_lower:\n","                matches.append((entity_id, 0.9))\n","            elif any(word in entity_text for word in text_lower.split()):\n","                matches.append((entity_id, 0.7))\n","\n","        matches = [(eid, score) for eid, score in matches if score >= threshold]\n","        matches.sort(key=lambda x: x[1], reverse=True)\n","        return [eid for eid, score in matches]\n","\n","    def get_direct_neighbors(self, entity_id: str, max_neighbors: int = 10) -> Dict[str, Any]:\n","        \"\"\"Get direct neighbors of an entity.\"\"\"\n","        results = []\n","\n","        # Forward neighbors\n","        for neighbor_info in self.adjacency_list.get(entity_id, []):\n","            neighbor_id = neighbor_info['target']\n","            if neighbor_id in self.entities:\n","                neighbor_data = self.entities[neighbor_id]\n","                results.append({\n","                    'neighbor_id': neighbor_id,\n","                    'neighbor_text': neighbor_data['text'],\n","                    'neighbor_type': neighbor_data['type'],\n","                    'relationship': neighbor_info['relationship'],\n","                    'confidence': neighbor_info['confidence']\n","                })\n","\n","        # Reverse neighbors\n","        for neighbor_info in self.reverse_adjacency.get(entity_id, []):\n","            neighbor_id = neighbor_info['source']\n","            if neighbor_id in self.entities:\n","                neighbor_data = self.entities[neighbor_id]\n","                results.append({\n","                    'neighbor_id': neighbor_id,\n","                    'neighbor_text': neighbor_data['text'],\n","                    'neighbor_type': neighbor_data['type'],\n","                    'relationship': neighbor_info['relationship'],\n","                    'confidence': neighbor_info['confidence']\n","                })\n","\n","        return {\n","            'entity_id': entity_id,\n","            'entity_text': self.entities.get(entity_id, {}).get('text', 'Unknown'),\n","            'neighbors': results[:max_neighbors]\n","        }\n","\n","    def find_multi_hop_paths(self, start_entity: str, end_entity: str, max_hops: int = 3) -> List[Dict]:\n","        \"\"\"Find paths between entities using BFS with confidence scoring.\"\"\"\n","        if start_entity == end_entity:\n","            return [{\n","                'node_path': [self.entities[start_entity]['text']],\n","                'rel_path': [],\n","                'path_confidence': 1.0,\n","                'path_length': 0\n","            }]\n","\n","        queue = deque([(start_entity, [start_entity], [], 1.0)])\n","        visited = set()\n","        paths = []\n","\n","        while queue and len(paths) < 10:\n","            current, path, relations, confidence = queue.popleft()\n","\n","            if len(path) > max_hops + 1:\n","                continue\n","\n","            if current == end_entity and len(path) > 1:\n","                node_path = [self.entities[node_id]['text'] for node_id in path]\n","                paths.append({\n","                    'node_path': node_path,\n","                    'rel_path': relations,\n","                    'path_confidence': confidence,\n","                    'path_length': len(path) - 1\n","                })\n","                continue\n","\n","            path_key = tuple(path)\n","            if path_key in visited:\n","                continue\n","            visited.add(path_key)\n","\n","            # Explore neighbors\n","            for neighbor_info in self.adjacency_list.get(current, []):\n","                neighbor = neighbor_info['target']\n","                if neighbor not in path:  # Avoid cycles\n","                    new_confidence = confidence * neighbor_info['confidence']\n","                    new_relations = relations + [neighbor_info['relationship']]\n","                    queue.append((neighbor, path + [neighbor], new_relations, new_confidence))\n","\n","        paths.sort(key=lambda x: (-x['path_confidence'], x['path_length']))\n","        return paths\n","\n","    def get_entity_subgraph(self, entity_ids: List[str], max_depth: int = 2) -> Dict[str, Any]:\n","        \"\"\"Extract a subgraph around given entities.\"\"\"\n","        subgraph_entities = set(entity_ids)\n","        subgraph_relationships = []\n","\n","        # BFS to expand subgraph\n","        current_level = set(entity_ids)\n","\n","        for depth in range(max_depth):\n","            next_level = set()\n","\n","            for entity_id in current_level:\n","                # Add forward neighbors\n","                for neighbor_info in self.adjacency_list.get(entity_id, []):\n","                    neighbor_id = neighbor_info['target']\n","                    next_level.add(neighbor_id)\n","                    subgraph_entities.add(neighbor_id)\n","\n","                    if entity_id in subgraph_entities and neighbor_id in subgraph_entities:\n","                        subgraph_relationships.append({\n","                            'source': entity_id,\n","                            'target': neighbor_id,\n","                            'relationship': neighbor_info['relationship'],\n","                            'confidence': neighbor_info['confidence']\n","                        })\n","\n","                # Add reverse neighbors\n","                for neighbor_info in self.reverse_adjacency.get(entity_id, []):\n","                    neighbor_id = neighbor_info['source']\n","                    next_level.add(neighbor_id)\n","                    subgraph_entities.add(neighbor_id)\n","\n","            current_level = next_level - subgraph_entities\n","\n","        return {\n","            'entities': {eid: self.entities[eid] for eid in subgraph_entities if eid in self.entities},\n","            'relationships': subgraph_relationships,\n","            'stats': {\n","                'entity_count': len(subgraph_entities),\n","                'relationship_count': len(subgraph_relationships),\n","                'max_depth': max_depth\n","            }\n","        }\n","\n","# Initialize graph traversal retriever\n","traversal_retriever = GraphTraversalRetriever(kg_data)\n","print(\"‚úÖ Graph traversal retriever initialized\")"],"metadata":{"id":"jNazpKQfWdAB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**# PART 2: ENTITY EMBEDDINGS**"],"metadata":{"id":"23mTAdHHWlZ3"}},{"cell_type":"code","source":["class GraphEntityEmbedder:\n","    \"\"\"Create and manage embeddings for graph entities.\"\"\"\n","\n","    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n","        try:\n","            self.embedding_model = SentenceTransformer(model_name)\n","            self.model_loaded = True\n","            print(f\"‚úÖ Embedding model loaded: {model_name}\")\n","        except Exception as e:\n","            print(f\"‚ö†Ô∏è Could not load embedding model: {e}\")\n","            print(\"Will use mock embeddings for demonstration\")\n","            self.model_loaded = False\n","\n","        self.entity_embeddings = {}\n","        self.embedding_index = None\n","\n","    def create_entity_embeddings(self, entities: Dict[str, Dict]) -> Dict[str, np.ndarray]:\n","        \"\"\"Create embeddings for all entities.\"\"\"\n","        if not self.model_loaded:\n","            return self._create_mock_embeddings(entities)\n","\n","        print(f\"üîÑ Creating embeddings for {len(entities)} entities...\")\n","\n","        embeddings = {}\n","        texts_to_embed = []\n","        entity_ids = []\n","\n","        for entity_id, entity_data in entities.items():\n","            entity_text = entity_data['text']\n","            entity_type = entity_data['type']\n","            enhanced_text = f\"{entity_type}: {entity_text}\"\n","            texts_to_embed.append(enhanced_text)\n","            entity_ids.append(entity_id)\n","\n","        try:\n","            embedding_vectors = self.embedding_model.encode(texts_to_embed, convert_to_numpy=True)\n","            for i, entity_id in enumerate(entity_ids):\n","                embeddings[entity_id] = embedding_vectors[i]\n","            print(f\"‚úÖ Created embeddings with dimension {embedding_vectors.shape[1]}\")\n","        except Exception as e:\n","            print(f\"‚ùå Error creating embeddings: {e}\")\n","            return self._create_mock_embeddings(entities)\n","\n","        self.entity_embeddings = embeddings\n","        return embeddings\n","\n","    def _create_mock_embeddings(self, entities: Dict[str, Dict]) -> Dict[str, np.ndarray]:\n","        \"\"\"Create mock embeddings for demonstration.\"\"\"\n","        embeddings = {}\n","        dimension = 384\n","        np.random.seed(42)\n","\n","        for entity_id, entity_data in entities.items():\n","            text_hash = hash(entity_data['text']) % 1000\n","            np.random.seed(text_hash)\n","            embedding = np.random.normal(0, 1, dimension)\n","            embedding = embedding / np.linalg.norm(embedding)\n","            embeddings[entity_id] = embedding\n","\n","        self.entity_embeddings = embeddings\n","        print(f\"‚úÖ Created {len(embeddings)} mock embeddings with dimension {dimension}\")\n","        return embeddings\n","\n","    def build_faiss_index(self) -> bool:\n","        \"\"\"Build FAISS index for efficient similarity search.\"\"\"\n","        if not self.entity_embeddings:\n","            print(\"‚ùå No embeddings available to index\")\n","            return False\n","\n","        try:\n","            entity_ids = list(self.entity_embeddings.keys())\n","            embedding_matrix = np.vstack([self.entity_embeddings[eid] for eid in entity_ids])\n","\n","            dimension = embedding_matrix.shape[1]\n","            self.embedding_index = faiss.IndexFlatIP(dimension)\n","\n","            faiss.normalize_L2(embedding_matrix)\n","            self.embedding_index.add(embedding_matrix)\n","\n","            self.entity_id_to_index = {entity_id: i for i, entity_id in enumerate(entity_ids)}\n","            self.index_to_entity_id = {i: entity_id for i, entity_id in enumerate(entity_ids)}\n","\n","            print(f\"‚úÖ FAISS index built with {len(entity_ids)} entities\")\n","            return True\n","        except Exception as e:\n","            print(f\"‚ùå Error building FAISS index: {e}\")\n","            return False\n","\n","    def semantic_search(self, query_text: str, top_k: int = 5) -> List[Dict[str, Any]]:\n","        \"\"\"Perform semantic search over entity embeddings.\"\"\"\n","        if not self.embedding_index:\n","            if not self.build_faiss_index():\n","                return []\n","\n","        try:\n","            if self.model_loaded:\n","                query_embedding = self.embedding_model.encode([query_text], convert_to_numpy=True)\n","            else:\n","                query_hash = hash(query_text) % 1000\n","                np.random.seed(query_hash)\n","                query_embedding = np.random.normal(0, 1, (1, 384))\n","                query_embedding = query_embedding / np.linalg.norm(query_embedding)\n","\n","            faiss.normalize_L2(query_embedding)\n","            scores, indices = self.embedding_index.search(query_embedding, top_k)\n","\n","            results = []\n","            for i, (score, idx) in enumerate(zip(scores[0], indices[0])):\n","                if idx in self.index_to_entity_id:\n","                    entity_id = self.index_to_entity_id[idx]\n","                    results.append({\n","                        'entity_id': entity_id,\n","                        'similarity_score': float(score),\n","                        'rank': i + 1\n","                    })\n","\n","            return results\n","        except Exception as e:\n","            print(f\"‚ùå Error in semantic search: {e}\")\n","            return []\n","\n","# Initialize entity embedder\n","entity_embedder = GraphEntityEmbedder()\n","embeddings = entity_embedder.create_entity_embeddings(kg_data['entities'])\n","entity_embedder.build_faiss_index()\n","print(\"‚úÖ Entity embeddings ready\")"],"metadata":{"id":"d36dyDclWlhW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**# PART 3: HYBRID GRAPH-VECTOR RETRIEVAL**"],"metadata":{"id":"mwt2UTEAW0GQ"}},{"cell_type":"code","source":["class HybridGraphVectorRetriever:\n","    \"\"\"Combine graph structure with semantic search for enhanced retrieval.\"\"\"\n","\n","    def __init__(self, graph_retriever: GraphTraversalRetriever, embedder: GraphEntityEmbedder):\n","        self.graph_retriever = graph_retriever\n","        self.embedder = embedder\n","        self.entities = graph_retriever.entities\n","        self.documents = graph_retriever.kg_data.get('documents', {})\n","\n","    def hybrid_search(self, query: str, top_k: int = 10, graph_weight: float = 0.5) -> List[Dict[str, Any]]:\n","        \"\"\"Perform hybrid search combining semantic similarity and graph structure.\"\"\"\n","        # Step 1: Semantic search\n","        semantic_results = self.embedder.semantic_search(query, top_k=top_k*2)\n","\n","        # Step 2: Expand with graph neighbors\n","        graph_expanded_entities = set()\n","        semantic_scores = {}\n","\n","        for result in semantic_results:\n","            entity_id = result['entity_id']\n","            semantic_score = result['similarity_score']\n","            semantic_scores[entity_id] = semantic_score\n","            graph_expanded_entities.add(entity_id)\n","\n","            # Add neighbors\n","            neighbors = self.graph_retriever.get_direct_neighbors(entity_id)\n","            for neighbor in neighbors['neighbors']:\n","                neighbor_id = neighbor['neighbor_id']\n","                neighbor_score = semantic_score * neighbor['confidence'] * 0.7\n","                if neighbor_id not in semantic_scores or semantic_scores[neighbor_id] < neighbor_score:\n","                    semantic_scores[neighbor_id] = neighbor_score\n","                graph_expanded_entities.add(neighbor_id)\n","\n","        # Step 3: Calculate combined scores\n","        hybrid_results = []\n","        for entity_id in graph_expanded_entities:\n","            entity_data = self.entities.get(entity_id, {})\n","            semantic_score = semantic_scores.get(entity_id, 0.0)\n","\n","            # Calculate graph centrality score\n","            neighbors = self.graph_retriever.get_direct_neighbors(entity_id)\n","            centrality_score = min(len(neighbors['neighbors']) / 10.0, 1.0)\n","\n","            # Combine scores\n","            hybrid_score = (graph_weight * centrality_score) + ((1 - graph_weight) * semantic_score)\n","\n","            hybrid_results.append({\n","                'entity_id': entity_id,\n","                'entity_text': entity_data.get('text', 'Unknown'),\n","                'entity_type': entity_data.get('type', 'Unknown'),\n","                'semantic_score': semantic_score,\n","                'centrality_score': centrality_score,\n","                'hybrid_score': hybrid_score\n","            })\n","\n","        hybrid_results.sort(key=lambda x: x['hybrid_score'], reverse=True)\n","        return hybrid_results[:top_k]\n","\n","    def retrieve_context_with_paths(self, query: str, max_entities: int = 5) -> Dict[str, Any]:\n","        \"\"\"Retrieve context including reasoning paths between entities.\"\"\"\n","        # Get top entities from hybrid search\n","        top_entities = self.hybrid_search(query, top_k=max_entities)\n","\n","        if len(top_entities) < 2:\n","            return {\n","                'entities': top_entities,\n","                'reasoning_paths': [],\n","                'documents': [],\n","                'subgraph': {}\n","            }\n","\n","        # Find reasoning paths between top entities\n","        reasoning_paths = []\n","        entity_ids = [e['entity_id'] for e in top_entities[:3]]\n","\n","        for i, start_id in enumerate(entity_ids):\n","            for end_id in entity_ids[i+1:]:\n","                paths = self.graph_retriever.find_multi_hop_paths(start_id, end_id, max_hops=2)\n","                if paths:\n","                    reasoning_paths.extend(paths[:2])\n","\n","        # Extract relevant subgraph\n","        subgraph = self.graph_retriever.get_entity_subgraph(entity_ids, max_depth=1)\n","\n","        # Find relevant documents\n","        relevant_docs = []\n","        for entity in top_entities:\n","            entity_id = entity['entity_id']\n","            for doc_id, doc_data in self.documents.items():\n","                if entity_id in doc_data.get('entities', []):\n","                    relevant_docs.append({\n","                        'document_id': doc_id,\n","                        'title': doc_data['title'],\n","                        'content': doc_data['content'][:200] + \"...\",\n","                        'matching_entity': entity['entity_text']\n","                    })\n","\n","        return {\n","            'entities': top_entities,\n","            'reasoning_paths': reasoning_paths,\n","            'documents': relevant_docs,\n","            'subgraph': subgraph\n","        }\n","\n","# Initialize hybrid retriever\n","hybrid_retriever = HybridGraphVectorRetriever(traversal_retriever, entity_embedder)\n","print(\"‚úÖ Hybrid graph-vector retriever initialized\")"],"metadata":{"id":"FqM4KbqyW0OF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**# PART 4: QUERY PROCESSING PIPELINE**"],"metadata":{"id":"TXGAxMhRW76h"}},{"cell_type":"code","source":["class GraphRAGQueryProcessor:\n","    \"\"\"Complete query processing pipeline for Graph RAG.\"\"\"\n","\n","    def __init__(self, hybrid_retriever: HybridGraphVectorRetriever):\n","        self.hybrid_retriever = hybrid_retriever\n","\n","    def process_query(self, query: str, max_context_entities: int = 5) -> Dict[str, Any]:\n","        \"\"\"Process a natural language query and return structured context.\"\"\"\n","        print(f\"üîç Processing query: '{query}'\")\n","\n","        # Retrieve relevant context\n","        context = self.hybrid_retriever.retrieve_context_with_paths(query, max_context_entities)\n","\n","        # Build context summary\n","        context_summary = self._build_context_summary(context)\n","\n","        # Prepare for LLM generation\n","        formatted_context = self._format_context_for_llm(context, query)\n","\n","        return {\n","            'original_query': query,\n","            'retrieved_entities': context['entities'],\n","            'reasoning_paths': context['reasoning_paths'],\n","            'relevant_documents': context['documents'],\n","            'context_summary': context_summary,\n","            'formatted_context': formatted_context\n","        }\n","\n","    def _build_context_summary(self, context: Dict) -> str:\n","        \"\"\"Build a human-readable context summary.\"\"\"\n","        summary_parts = []\n","\n","        if context['entities']:\n","            entity_texts = [e['entity_text'] for e in context['entities'][:3]]\n","            summary_parts.append(f\"Key entities: {', '.join(entity_texts)}\")\n","\n","        if context['reasoning_paths']:\n","            path_count = len(context['reasoning_paths'])\n","            summary_parts.append(f\"Found {path_count} reasoning paths connecting entities\")\n","\n","        if context['documents']:\n","            doc_count = len(context['documents'])\n","            summary_parts.append(f\"Referenced in {doc_count} documents\")\n","\n","        return \". \".join(summary_parts) + \".\" if summary_parts else \"No relevant context found.\"\n","\n","    def _format_context_for_llm(self, context: Dict, query: str) -> str:\n","        \"\"\"Format retrieved context for LLM consumption.\"\"\"\n","        formatted_parts = []\n","\n","        if context['entities']:\n","            formatted_parts.append(\"=== RELEVANT ENTITIES ===\")\n","            for entity in context['entities'][:5]:\n","                formatted_parts.append(f\"- {entity['entity_text']} ({entity['entity_type']})\")\n","                formatted_parts.append(f\"  Relevance score: {entity['hybrid_score']:.3f}\")\n","\n","        if context['reasoning_paths']:\n","            formatted_parts.append(\"\\n=== REASONING PATHS ===\")\n","            for i, path in enumerate(context['reasoning_paths'][:3], 1):\n","                formatted_parts.append(f\"{i}. {' -> '.join(path['node_path'])}\")\n","                formatted_parts.append(f\"   Relationships: {' -> '.join(path['rel_path'])}\")\n","                formatted_parts.append(f\"   Confidence: {path['path_confidence']:.3f}\")\n","\n","        if context['documents']:\n","            formatted_parts.append(\"\\n=== RELEVANT DOCUMENTS ===\")\n","            for doc in context['documents'][:3]:\n","                formatted_parts.append(f\"Title: {doc['title']}\")\n","                formatted_parts.append(f\"Content: {doc['content']}\")\n","                formatted_parts.append(f\"Relevant entity: {doc['matching_entity']}\")\n","                formatted_parts.append(\"\")\n","\n","        return \"\\n\".join(formatted_parts)\n","\n","# Initialize query processor\n","query_processor = GraphRAGQueryProcessor(hybrid_retriever)\n","print(\"‚úÖ Graph RAG query processor initialized\")"],"metadata":{"id":"6sI_5ddqW8B0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**# DEMONSTRATIONS**"],"metadata":{"id":"Tgnmt5kQXDki"}},{"cell_type":"code","source":["def demonstrate_graph_traversal():\n","    \"\"\"Demonstrate graph traversal capabilities.\"\"\"\n","    print(\"\\n=== GRAPH TRAVERSAL DEMONSTRATIONS ===\")\n","\n","    # 1. Entity lookup and direct neighbors\n","    print(\"\\n1. Finding entities and their direct neighbors:\")\n","    search_terms = [\"Transformer\", \"attention\", \"BERT\"]\n","\n","    for term in search_terms:\n","        print(f\"\\n   Searching for: '{term}'\")\n","        entity_ids = traversal_retriever.find_entity_by_text(term)\n","\n","        if entity_ids:\n","            entity_id = entity_ids[0]\n","            neighbors = traversal_retriever.get_direct_neighbors(entity_id, max_neighbors=5)\n","\n","            print(f\"   Found entity: {neighbors['entity_text']} (ID: {entity_id})\")\n","            print(f\"   Direct neighbors:\")\n","\n","            for neighbor in neighbors['neighbors']:\n","                print(f\"     ‚Ä¢ {neighbor['neighbor_text']} via {neighbor['relationship']} (conf: {neighbor['confidence']:.2f})\")\n","        else:\n","            print(f\"   No entities found for '{term}'\")\n","\n","    # 2. Multi-hop path finding\n","    print(\"\\n\\n2. Multi-hop reasoning paths:\")\n","    path_queries = [\n","        (\"concept_2\", \"concept_1\", \"BERT to attention mechanisms\"),\n","        (\"person_0\", \"metric_0\", \"Ashish Vaswani to BLEU metric\"),\n","    ]\n","\n","    for start_id, end_id, description in path_queries:\n","        print(f\"\\n   Path query: {description}\")\n","        paths = traversal_retriever.find_multi_hop_paths(start_id, end_id, max_hops=3)\n","\n","        if paths:\n","            for i, path in enumerate(paths[:2], 1):\n","                print(f\"     Path {i}: {' -> '.join(path['node_path'])}\")\n","                print(f\"       Relations: {' -> '.join(path['rel_path'])}\")\n","                print(f\"       Confidence: {path['path_confidence']:.3f}, Length: {path['path_length']}\")\n","        else:\n","            print(f\"     No paths found\")\n","\n","def demonstrate_hybrid_retrieval():\n","    \"\"\"Demonstrate hybrid graph-vector retrieval.\"\"\"\n","    print(\"\\n=== HYBRID GRAPH-VECTOR RETRIEVAL DEMONSTRATIONS ===\")\n","\n","    test_queries = [\n","        \"neural network architecture for language understanding\",\n","        \"attention mechanism evaluation metrics\",\n","        \"transformer model performance\"\n","    ]\n","\n","    for query in test_queries:\n","        print(f\"\\nQuery: '{query}'\")\n","        print(\"-\" * 50)\n","\n","        # Hybrid search\n","        results = hybrid_retriever.hybrid_search(query, top_k=5)\n","\n","        print(\"Top entities (hybrid search):\")\n","        for i, result in enumerate(results, 1):\n","            print(f\"  {i}. {result['entity_text']} ({result['entity_type']})\")\n","            print(f\"     Semantic: {result['semantic_score']:.3f}, Centrality: {result['centrality_score']:.3f}, Hybrid: {result['hybrid_score']:.3f}\")\n","\n","        # Context retrieval with paths\n","        context = hybrid_retriever.retrieve_context_with_paths(query, max_entities=3)\n","\n","        if context['reasoning_paths']:\n","            print(\"\\nReasoning paths:\")\n","            for i, path in enumerate(context['reasoning_paths'][:2], 1):\n","                print(f\"  Path {i}: {' -> '.join(path['node_path'])}\")\n","                print(f\"    Relations: {' -> '.join(path['rel_path'])}\")\n","\n","        if context['documents']:\n","            print(f\"\\nRelevant documents:\")\n","            for doc in context['documents'][:2]:\n","                print(f\"  ‚Ä¢ {doc['title']} (via {doc['matching_entity']})\")\n","\n","def demonstrate_query_processing():\n","    \"\"\"Demonstrate complete query processing pipeline.\"\"\"\n","    print(\"\\n=== COMPLETE QUERY PROCESSING DEMONSTRATIONS ===\")\n","\n","    complex_queries = [\n","        \"How does the Transformer architecture relate to BERT?\",\n","        \"What evaluation metrics are used for machine translation models?\",\n","        \"Who introduced the attention mechanism and how is it used?\"\n","    ]\n","\n","    for query in complex_queries:\n","        print(f\"\\nProcessing: '{query}'\")\n","        print(\"=\" * 60)\n","\n","        result = query_processor.process_query(query, max_context_entities=4)\n","\n","        print(f\"Context Summary: {result['context_summary']}\")\n","        print()\n","\n","        print(\"Retrieved Entities:\")\n","        for entity in result['retrieved_entities'][:3]:\n","            print(f\"  ‚Ä¢ {entity['entity_text']} ({entity['entity_type']}) - Score: {entity['hybrid_score']:.3f}\")\n","        print()\n","\n","        if result['reasoning_paths']:\n","            print(\"Key Reasoning Paths:\")\n","            for i, path in enumerate(result['reasoning_paths'][:2], 1):\n","                print(f\"  {i}. {' ‚Üí '.join(path['node_path'])}\")\n","                print(f\"     Via: {' ‚Üí '.join(path['rel_path'])}\")\n","        print()\n","\n","        if result['relevant_documents']:\n","            print(\"Relevant Documents:\")\n","            for doc in result['relevant_documents'][:2]:\n","                print(f\"  ‚Ä¢ {doc['title']} (mentions {doc['matching_entity']})\")"],"metadata":{"id":"zy7Dbx8eXDra","executionInfo":{"status":"ok","timestamp":1748191979712,"user_tz":-330,"elapsed":26,"user":{"displayName":"ranajoy bose","userId":"06328792273740913169"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["**# PERFORMANCE ANALYSIS**"],"metadata":{"id":"VTCQ18hjXLHG"}},{"cell_type":"code","source":["def analyze_retrieval_performance():\n","    \"\"\"Analyze performance of different retrieval approaches.\"\"\"\n","    print(\"\\n=== RETRIEVAL PERFORMANCE ANALYSIS ===\")\n","\n","    test_queries = [\n","        \"transformer attention mechanism\",\n","        \"BERT language model\",\n","        \"machine translation evaluation\",\n","        \"neural network architecture\",\n","        \"deep learning research\"\n","    ]\n","\n","    performance_results = []\n","\n","    for query in test_queries:\n","        print(f\"Analyzing query: '{query}'\")\n","\n","        # Semantic-only search\n","        semantic_results = entity_embedder.semantic_search(query, top_k=5)\n","        semantic_entities = [r['entity_id'] for r in semantic_results]\n","\n","        # Graph-only expansion\n","        graph_entities = set()\n","        if semantic_entities:\n","            top_entity = semantic_entities[0]\n","            neighbors = traversal_retriever.get_direct_neighbors(top_entity)\n","            graph_entities = {n['neighbor_id'] for n in neighbors['neighbors']}\n","            graph_entities.add(top_entity)\n","\n","        # Hybrid approach\n","        hybrid_results = hybrid_retriever.hybrid_search(query, top_k=5)\n","        hybrid_entities = [r['entity_id'] for r in hybrid_results]\n","\n","        # Calculate coverage\n","        all_entities = set(semantic_entities + list(graph_entities) + hybrid_entities)\n","\n","        performance_results.append({\n","            'query': query,\n","            'semantic_count': len(semantic_entities),\n","            'graph_count': len(graph_entities),\n","            'hybrid_count': len(hybrid_entities),\n","            'total_unique': len(all_entities)\n","        })\n","\n","    # Display performance summary\n","    print(\"\\nPerformance Summary:\")\n","    print(\"-\" * 50)\n","\n","    df = pd.DataFrame(performance_results)\n","\n","    print(f\"Average entities retrieved:\")\n","    print(f\"  Semantic-only: {df['semantic_count'].mean():.1f}\")\n","    print(f\"  Graph-expanded: {df['graph_count'].mean():.1f}\")\n","    print(f\"  Hybrid approach: {df['hybrid_count'].mean():.1f}\")\n","    print(f\"  Total unique coverage: {df['total_unique'].mean():.1f}\")"],"metadata":{"id":"KlaKaKFVXLPJ","executionInfo":{"status":"ok","timestamp":1748192008829,"user_tz":-330,"elapsed":44,"user":{"displayName":"ranajoy bose","userId":"06328792273740913169"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["**# VISUALIZATION**"],"metadata":{"id":"LpOiFix4XSD5"}},{"cell_type":"code","source":["def visualize_retrieval_results(query: str):\n","    \"\"\"Visualize the retrieval results for a given query.\"\"\"\n","    print(f\"\\n=== VISUALIZING RETRIEVAL FOR: '{query}' ===\")\n","\n","    # Get retrieval results\n","    context = hybrid_retriever.retrieve_context_with_paths(query, max_entities=5)\n","\n","    # Create NetworkX graph for visualization\n","    G = nx.Graph()\n","\n","    # Add nodes\n","    node_colors = []\n","    node_sizes = []\n","\n","    for entity in context['entities']:\n","        entity_id = entity['entity_id']\n","        entity_text = entity['entity_text']\n","        entity_type = entity['entity_type']\n","\n","        G.add_node(entity_id,\n","                  text=entity_text,\n","                  type=entity_type,\n","                  score=entity['hybrid_score'])\n","\n","        # Color by entity type\n","        if entity_type == 'CONCEPT':\n","            node_colors.append('lightblue')\n","        elif entity_type == 'PERSON':\n","            node_colors.append('lightgreen')\n","        elif entity_type == 'METRIC':\n","            node_colors.append('orange')\n","        elif entity_type == 'DATASET':\n","            node_colors.append('pink')\n","        else:\n","            node_colors.append('lightgray')\n","\n","        # Size by relevance score\n","        node_sizes.append(300 + entity['hybrid_score'] * 1000)\n","\n","    # Add edges from subgraph\n","    if 'subgraph' in context and context['subgraph']:\n","        for rel in context['subgraph'].get('relationships', []):\n","            source_id = rel['source']\n","            target_id = rel['target']\n","\n","            if source_id in G.nodes and target_id in G.nodes:\n","                G.add_edge(source_id, target_id,\n","                          relationship=rel['relationship'],\n","                          confidence=rel['confidence'])\n","\n","    # Create visualization\n","    plt.figure(figsize=(12, 8))\n","\n","    # Use spring layout for positioning\n","    pos = nx.spring_layout(G, k=2, iterations=50)\n","\n","    # Draw the graph\n","    nx.draw(G, pos,\n","            node_color=node_colors,\n","            node_size=node_sizes,\n","            font_size=8,\n","            font_weight='bold',\n","            edge_color='gray',\n","            width=2,\n","            alpha=0.7,\n","            with_labels=False)\n","\n","    # Add custom labels\n","    labels = {}\n","    for node_id in G.nodes():\n","        node_data = G.nodes[node_id]\n","        labels[node_id] = node_data['text'][:15] + (\"...\" if len(node_data['text']) > 15 else \"\")\n","\n","    nx.draw_networkx_labels(G, pos, labels, font_size=8)\n","\n","    # Add title and legend\n","    plt.title(f\"Graph Retrieval Results for: '{query}'\", size=14, weight='bold')\n","\n","    # Create legend\n","    from matplotlib.patches import Patch\n","    legend_elements = [\n","        Patch(facecolor='lightblue', label='Concepts'),\n","        Patch(facecolor='lightgreen', label='People'),\n","        Patch(facecolor='orange', label='Metrics'),\n","        Patch(facecolor='pink', label='Datasets')\n","    ]\n","    plt.legend(handles=legend_elements, loc='upper right')\n","\n","    plt.axis('off')\n","    plt.tight_layout()\n","    plt.show()\n","\n","    # Print detailed results\n","    print(f\"\\nDetailed Results:\")\n","    print(f\"Retrieved {len(context['entities'])} entities\")\n","    print(f\"Found {len(context['reasoning_paths'])} reasoning paths\")\n","    print(f\"Connected to {len(context['documents'])} documents\")"],"metadata":{"id":"ITH-uZa7XSKr","executionInfo":{"status":"ok","timestamp":1748194206805,"user_tz":-330,"elapsed":32,"user":{"displayName":"ranajoy bose","userId":"06328792273740913169"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["**# EXPORT AND INTEGRATION**"],"metadata":{"id":"nLkIrlM1fq0D"}},{"cell_type":"code","source":["def export_retrieval_results(output_file: str = \"graph_retrieval_results.json\"):\n","    \"\"\"Export retrieval capabilities and results for integration.\"\"\"\n","    print(f\"üì§ Exporting retrieval results to {output_file}\")\n","\n","    test_queries = [\n","        \"transformer neural network architecture\",\n","        \"BERT language understanding model\",\n","        \"attention mechanism evaluation metrics\"\n","    ]\n","\n","    export_data = {\n","        'retrieval_capabilities': {\n","            'graph_traversal': True,\n","            'semantic_search': True,\n","            'hybrid_retrieval': True,\n","            'multi_hop_reasoning': True,\n","            'subgraph_extraction': True\n","        },\n","        'knowledge_graph_stats': {\n","            'total_entities': len(kg_data['entities']),\n","            'total_relationships': len(kg_data['relationships']),\n","            'entity_types': list(set(e['type'] for e in kg_data['entities'].values())),\n","            'relationship_types': list(set(r['type'] for r in kg_data['relationships']))\n","        },\n","        'sample_queries': {},\n","        'performance_metrics': {\n","            'avg_entities_per_query': 0,\n","            'avg_paths_per_query': 0,\n","            'avg_documents_per_query': 0\n","        }\n","    }\n","\n","    total_entities = 0\n","    total_paths = 0\n","    total_docs = 0\n","\n","    for query in test_queries:\n","        print(f\"   Processing: {query}\")\n","\n","        result = query_processor.process_query(query, max_context_entities=5)\n","\n","        export_data['sample_queries'][query] = {\n","            'retrieved_entities': len(result['retrieved_entities']),\n","            'reasoning_paths': len(result['reasoning_paths']),\n","            'relevant_documents': len(result['relevant_documents']),\n","            'context_summary': result['context_summary'],\n","            'top_entities': [\n","                {\n","                    'text': e['entity_text'],\n","                    'type': e['entity_type'],\n","                    'score': e['hybrid_score']\n","                } for e in result['retrieved_entities'][:3]\n","            ]\n","        }\n","\n","        total_entities += len(result['retrieved_entities'])\n","        total_paths += len(result['reasoning_paths'])\n","        total_docs += len(result['relevant_documents'])\n","\n","    # Calculate averages\n","    num_queries = len(test_queries)\n","    export_data['performance_metrics'] = {\n","        'avg_entities_per_query': total_entities / num_queries,\n","        'avg_paths_per_query': total_paths / num_queries,\n","        'avg_documents_per_query': total_docs / num_queries\n","    }\n","\n","    # Save to file\n","    with open(output_file, 'w') as f:\n","        json.dump(export_data, f, indent=2, default=str)\n","\n","    print(f\"‚úÖ Exported retrieval results and capabilities\")\n","    print(f\"   Queries processed: {num_queries}\")\n","    print(f\"   Average entities per query: {export_data['performance_metrics']['avg_entities_per_query']:.1f}\")\n","    print(f\"   Average reasoning paths per query: {export_data['performance_metrics']['avg_paths_per_query']:.1f}\")\n"],"metadata":{"id":"JZyo6u38fq9h","executionInfo":{"status":"ok","timestamp":1748194234746,"user_tz":-330,"elapsed":47,"user":{"displayName":"ranajoy bose","userId":"06328792273740913169"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["**# RUN ALL DEMONSTRATIONS**"],"metadata":{"id":"LS4SzgZkfxi3"}},{"cell_type":"code","source":["print(\"\\n\" + \"=\"*80)\n","print(\"üöÄ RUNNING ALL DEMONSTRATIONS\")\n","print(\"=\"*80)\n","\n","# Run demonstrations\n","demonstrate_graph_traversal()\n","demonstrate_hybrid_retrieval()\n","demonstrate_query_processing()\n","analyze_retrieval_performance()\n","\n","# Visualize results for a sample query\n","visualize_retrieval_results(\"transformer attention mechanism evaluation\")\n","\n","# Export results\n","export_retrieval_results()"],"metadata":{"id":"hmqsDBCrfxrC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**# SUMMARY AND NEXT STEPS**"],"metadata":{"id":"pfDNIVDUf8si"}},{"cell_type":"code","source":["def chapter_summary():\n","    \"\"\"Summarize what we've accomplished in this notebook.\"\"\"\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"üìã CHAPTER 12.4 SUMMARY - Graph-Enhanced Retrieval\")\n","    print(\"=\"*60)\n","\n","    print(\"\\n‚úÖ What you've implemented:\")\n","    accomplishments = [\n","        \"Graph traversal for multi-hop reasoning\",\n","        \"Entity-based semantic search with embeddings\",\n","        \"Hybrid graph-vector retrieval combining structure and semantics\",\n","        \"Subgraph extraction for focused context\",\n","        \"Complete query processing pipeline\",\n","        \"Performance analysis and optimization techniques\",\n","        \"Visualization of retrieval results\"\n","    ]\n","\n","    for item in accomplishments:\n","        print(f\"   ‚Ä¢ {item}\")\n","\n","    print(f\"\\nüìä Key Metrics:\")\n","    print(f\"   ‚Ä¢ Knowledge graph entities: {len(kg_data['entities'])}\")\n","    print(f\"   ‚Ä¢ Knowledge graph relationships: {len(kg_data['relationships'])}\")\n","    print(f\"   ‚Ä¢ Entity embedding dimension: 384\")\n","    print(f\"   ‚Ä¢ Max reasoning hops: 3\")\n","\n","    print(f\"\\nüéØ Key Capabilities Demonstrated:\")\n","    capabilities = [\n","        \"Multi-hop path finding between entities\",\n","        \"Semantic similarity search over graph entities\",\n","        \"Hybrid scoring combining graph structure and semantics\",\n","        \"Context-aware subgraph extraction\",\n","        \"Reasoning path explanation and visualization\"\n","    ]\n","\n","    for capability in capabilities:\n","        print(f\"   ‚Ä¢ {capability}\")\n","\n","    print(f\"\\nüöÄ Ready for Next Steps:\")\n","    next_steps = [\n","        \"Integration with LLMs for natural language generation (Notebook 12.5)\",\n","        \"End-to-end Graph RAG system implementation\",\n","        \"Advanced reasoning patterns and query optimization\",\n","        \"Production deployment and scaling considerations\"\n","    ]\n","\n","    for step in next_steps:\n","        print(f\"   ‚Ä¢ {step}\")\n","\n","    print(f\"\\nüí° Key Insights:\")\n","    insights = [\n","        \"Graph structure provides explainable reasoning paths\",\n","        \"Hybrid retrieval outperforms single-method approaches\",\n","        \"Entity embeddings enable semantic understanding of graph content\",\n","        \"Multi-hop reasoning reveals non-obvious connections\",\n","        \"Visualization helps debug and understand retrieval quality\"\n","    ]\n","\n","    for insight in insights:\n","        print(f\"   ‚Ä¢ {insight}\")\n","\n","def prepare_for_next_notebook():\n","    \"\"\"Prepare data and components for the next notebook.\"\"\"\n","    print(\"\\nüìã PREPARING FOR NOTEBOOK 12.5\")\n","    print(\"=\"*40)\n","\n","    # Save key components for next notebook\n","    graph_rag_components = {\n","        'traversal_retriever': 'GraphTraversalRetriever initialized',\n","        'entity_embedder': 'GraphEntityEmbedder with FAISS index',\n","        'hybrid_retriever': 'HybridGraphVectorRetriever ready',\n","        'query_processor': 'GraphRAGQueryProcessor configured',\n","        'knowledge_graph': f\"{len(kg_data['entities'])} entities, {len(kg_data['relationships'])} relationships\"\n","    }\n","\n","    print(\"‚úÖ Components ready for Graph RAG integration:\")\n","    for component, status in graph_rag_components.items():\n","        print(f\"   ‚Ä¢ {component}: {status}\")\n","\n","    # Save configuration for next notebook\n","    config = {\n","        'embedding_model': 'all-MiniLM-L6-v2',\n","        'max_hops': 3,\n","        'max_entities': 5,\n","        'graph_weight': 0.5,\n","        'top_k_default': 10\n","    }\n","\n","    with open('graph_retrieval_config.json', 'w') as f:\n","        json.dump(config, f, indent=2)\n","\n","    print(f\"\\nüíæ Configuration saved to 'graph_retrieval_config.json'\")\n","    print(f\"üîÑ All components initialized and ready for Graph RAG system integration\")\n","\n","# Run final summary and preparation\n","chapter_summary()\n","prepare_for_next_notebook()\n"],"metadata":{"id":"ODvIW9Ijf80Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**# TROUBLESHOOTING GUIDE**"],"metadata":{"id":"EYmNppMKgEVl"}},{"cell_type":"code","source":["print(\"\\n\" + \"=\"*60)\n","print(\"üîß TROUBLESHOOTING GUIDE\")\n","print(\"=\"*60)\n","\n","troubleshooting_tips = [\n","    {\n","        \"issue\": \"FAISS installation errors\",\n","        \"solution\": \"Use 'pip install faiss-cpu' instead of 'faiss-gpu' in Colab\"\n","    },\n","    {\n","        \"issue\": \"Sentence Transformers slow loading\",\n","        \"solution\": \"First run may be slow due to model download, subsequent runs faster\"\n","    },\n","    {\n","        \"issue\": \"Memory issues with large graphs\",\n","        \"solution\": \"Reduce max_entities, max_hops, or process in smaller batches\"\n","    },\n","    {\n","        \"issue\": \"Low retrieval quality\",\n","        \"solution\": \"Adjust graph_weight parameter, try different embedding models\"\n","    },\n","    {\n","        \"issue\": \"Visualization not displaying\",\n","        \"solution\": \"Ensure matplotlib is installed and try plt.show() explicitly\"\n","    }\n","]\n","\n","for tip in troubleshooting_tips:\n","    print(f\"‚ùå {tip['issue']}\")\n","    print(f\"‚úÖ {tip['solution']}\\n\")\n","\n","print(\"üìö For more help, refer to the chapter text and previous notebooks.\")\n","print(\"üéØ Ready to proceed to Notebook 12.5: Complete Graph RAG System!\")\n","\n","print(f\"\\nüéâ Graph-Enhanced Retrieval Implementation Complete!\")\n","print(f\"Continue to Notebook 12.5 to build the complete Graph RAG system.\")"],"metadata":{"id":"lvkdOdGxgEc5"},"execution_count":null,"outputs":[]}]}