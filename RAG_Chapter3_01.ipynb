{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install langchain-community langchain-openai chromadb"
      ],
      "metadata": {
        "id": "bf9F-FJ5--40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries for RAG application\n",
        "import os  # OS interactions and environment variables\n",
        "\n",
        "# Document loading and vector store components\n",
        "from langchain_community.document_loaders import WebBaseLoader  # Load documents from web\n",
        "from langchain_community.vectorstores import Chroma  # Vector storage and retrieval\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter  # Splitting documents into chunks\n",
        "\n",
        "# Embedding and language model components\n",
        "from langchain_openai import OpenAIEmbeddings  # Generate vector embeddings\n",
        "from langchain_openai import ChatOpenAI  # OpenAI language model\n",
        "\n",
        "# LangChain core components for RAG pipeline\n",
        "from langchain_core.prompts import ChatPromptTemplate  # Create prompt templates\n",
        "from langchain_core.output_parsers import StrOutputParser  # Parse model outputs\n",
        "from langchain_core.runnables import RunnablePassthrough  # Create runnable sequences"
      ],
      "metadata": {
        "id": "IkWlngEG-07B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set OpenAI API Key (replace with your actual key)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "MFmXIOy5_es8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load documents from a webpage\n",
        "loader = WebBaseLoader(\"https://docs.smith.langchain.com\")\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "MPYdFQGi_iZ7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split documents into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "5m9wEgi5_lkV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create vector store\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())"
      ],
      "metadata": {
        "id": "sIYN5km4_p2D"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create retriever\n",
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "ZQPCDYrC_tR0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define RAG prompt\n",
        "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "TV1jcQw2_xI_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize language model\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
      ],
      "metadata": {
        "id": "V8vkn_qU_33B"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create RAG chain\n",
        "rag_chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "FhITu23c_74A"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "def ask_question(question):\n",
        "    return rag_chain.invoke(question)"
      ],
      "metadata": {
        "id": "OGqdisCQBBZD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Demonstrate the RAG application\n",
        "print(\"Question: What is LangSmith?\")\n",
        "response = ask_question(\"What is LangSmith?\")\n",
        "print(\"\\nResponse:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4qp3GhzBEDi",
        "outputId": "a5a1399e-0b5e-4a7d-e9a0-2144e3d6d4c1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is LangSmith?\n",
            "\n",
            "Response: LangSmith is a platform for building production-grade LLM applications.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add source retrieval (new lines)\n",
        "print(\"\\nSources:\")\n",
        "sources = retriever.invoke(\"What is LangSmith?\")\n",
        "for i, source in enumerate(sources, 1):\n",
        "    print(f\"\\nSource {i}:\")\n",
        "    print(\"Content:\", source.page_content[:500] + \"...\" if len(source.page_content) > 500 else source.page_content)\n",
        "    print(\"Source URL:\", source.metadata.get('source', 'Unknown source'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8f2MIrZMkkA",
        "outputId": "81f7d743-d200-416d-cee2-a5316e86408e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sources:\n",
            "\n",
            "Source 1:\n",
            "Content: Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Skip to main contentLearn the essentials of LangSmith in the new Introduction to LangSmith course!  Enroll for free. API ReferenceRESTPythonJS/TSSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referenceQuick...\n",
            "Source URL: https://docs.smith.langchain.com\n",
            "\n",
            "Source 2:\n",
            "Content: LangSmith + LangChain OSSLangSmith integrates seamlessly with LangChain's open source frameworks langchain and langgraph, with no extra instrumentation needed.If you're already using either of these, see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\n",
            "LangSmith is a standalone platform that can be used on it's own no matter how you're creating your LLM applicatons.\n",
            "In this tutorial, we'll walk you though logging your first trace in LangSmith using...\n",
            "Source URL: https://docs.smith.langchain.com\n",
            "\n",
            "Source 3:\n",
            "Content: Click the link printed out by your evaluation run to access the LangSmith experiments UI,\n",
            "and explore the results of your evaluation.\n",
            "Learn more about evaluation in the tutorials, conceptual guide, and how-to guides.\n",
            "Was this page helpful?You can leave detailed feedback on GitHub.NextObservability tutorials1. Install LangSmith2. Create an API key3. Set up your environment4. Log your first trace5. View your trace6. Run your first evaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPython...\n",
            "Source URL: https://docs.smith.langchain.com\n",
            "\n",
            "Source 4:\n",
            "Content: 2. Create an API key‚Äã\n",
            "To create an API key head to the Settings page. Then click Create API Key.\n",
            "3. Set up your environment‚Äã\n",
            "Shellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key>export OPENAI_API_KEY=<your-openai-api-key>\n",
            "4. Log your first trace‚Äã\n",
            "We provide multiple ways to log traces to LangSmith. Below, we'll highlight\n",
            "how to use traceable(). See more on the Annotate code for tracing page.\n",
            "Source URL: https://docs.smith.langchain.com\n"
          ]
        }
      ]
    }
  ]
}