{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMrkMrYEZaGZVx0hmYpP9WD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Install required packages\n","!pip install langchain\n","!pip install langchain-community\n","!pip install langchain-text-splitters\n","!pip install transformers\n","!pip install torch\n","\n","# Now import the required modules\n","from langchain_text_splitters import RecursiveCharacterTextSplitter\n","from langchain_community.embeddings import HuggingFaceEmbeddings\n","import numpy as np\n","from typing import List, Dict\n","\n","class SemanticTextSplitter:\n","    \"\"\"Split text based on semantic meaning using embeddings\"\"\"\n","    def __init__(self,\n","                 chunk_size: int = 1000,\n","                 chunk_overlap: int = 200):\n","        self.chunk_size = chunk_size\n","        self.chunk_overlap = chunk_overlap\n","        self.embeddings = HuggingFaceEmbeddings()"],"metadata":{"id":"_dJrdG2mg1IO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Example Scenarios**"],"metadata":{"id":"FAXuWLjYhXoA"}},{"cell_type":"code","source":["class SemanticTextSplitter:\n","   \"\"\"Split text based on semantic meaning using embeddings\"\"\"\n","   def __init__(self,\n","                chunk_size: int = 1000,\n","                chunk_overlap: int = 200):\n","       self.chunk_size = chunk_size\n","       self.chunk_overlap = chunk_overlap\n","       self.embeddings = HuggingFaceEmbeddings()\n","\n","   def split_by_semantic_similarity(self, text: str) -> List[str]:\n","       \"\"\"Split text based on semantic similarity between sections\"\"\"\n","       # Initial split into paragraphs\n","       paragraphs = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n","\n","       # Get embeddings for paragraphs\n","       embeddings = [self.embeddings.embed_query(p) for p in paragraphs]\n","\n","       # Initialize chunks\n","       chunks = []\n","       current_chunk = [paragraphs[0]]\n","       current_emb = embeddings[0]\n","\n","       # Group similar paragraphs\n","       for i in range(1, len(paragraphs)):\n","           # Calculate similarity with current chunk\n","           similarity = np.dot(current_emb, embeddings[i])\n","\n","           if similarity > 0.7:  # Threshold for semantic similarity\n","               current_chunk.append(paragraphs[i])\n","           else:\n","               # Save current chunk and start new one\n","               chunks.append('\\n\\n'.join(current_chunk))\n","               current_chunk = [paragraphs[i]]\n","               current_emb = embeddings[i]\n","\n","       # Add final chunk\n","       if current_chunk:\n","           chunks.append('\\n\\n'.join(current_chunk))\n","\n","       return chunks\n","\n","def test_semantic_splitting():\n","   \"\"\"Test semantic text splitting with example documents\"\"\"\n","\n","   # Test document with distinct topics\n","   test_doc = \"\"\"\n","   Machine Learning Fundamentals\n","   Machine learning models learn from data patterns. They can identify\n","   complex relationships and make predictions. Training requires large\n","   datasets and computational resources.\n","\n","   Climate Change Effects\n","   Global temperatures are rising at unprecedented rates. This causes\n","   melting ice caps and rising sea levels. Many species are at risk\n","   due to habitat changes.\n","\n","   Space Exploration Progress\n","   Recent Mars missions have provided new insights. Private companies\n","   are now leading space innovation. The search for extraterrestrial\n","   life continues.\n","   \"\"\"\n","\n","   splitter = SemanticTextSplitter()\n","   chunks = splitter.split_by_semantic_similarity(test_doc)\n","\n","   print(\"Semantic Splitting Results:\")\n","   for i, chunk in enumerate(chunks, 1):\n","       print(f\"\\nChunk {i}:\")\n","       print(\"-\" * 50)\n","       print(chunk)\n","       print(\"-\" * 50)\n","\n","# Advanced usage example\n","def process_technical_document():\n","   \"\"\"Process a technical document with mixed content\"\"\"\n","\n","   technical_doc = \"\"\"\n","   Neural Network Architecture\n","   Neural networks consist of layers of neurons. Each neuron processes\n","   inputs through an activation function. The network learns by adjusting\n","   connection weights.\n","\n","   Training Process\n","   Training involves forward propagation of data and backpropagation\n","   of errors. The network adjusts weights to minimize loss. Regular\n","   validation prevents overfitting.\n","\n","   Applications in Computer Vision\n","   Computer vision uses neural networks for image recognition.\n","   Convolutional layers extract features automatically. This enables\n","   accurate object detection and classification.\n","   \"\"\"\n","\n","   splitter = SemanticTextSplitter(chunk_size=500)\n","   chunks = splitter.split_by_semantic_similarity(technical_doc)\n","\n","   print(\"\\nTechnical Document Processing:\")\n","   for i, chunk in enumerate(chunks, 1):\n","       print(f\"\\nSection {i}:\")\n","       print(\"-\" * 50)\n","       print(chunk)\n","       print(\"-\" * 50)\n","\n","if __name__ == \"__main__\":\n","   test_semantic_splitting()\n","   process_technical_document()"],"metadata":{"id":"AGwH8u9bhZds"},"execution_count":null,"outputs":[]}]}