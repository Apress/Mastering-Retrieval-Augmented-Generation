{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMA/M7b7KNkhMaNowjVgY5m"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Setup and Installation**"],"metadata":{"id":"QNInGh3KtYJt"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"mYjiDIxvs7D8"},"outputs":[],"source":["!pip install langchain langchain-openai tiktoken pillow matplotlib pandas\n","\n","import os\n","import re\n","import json\n","import base64\n","from io import BytesIO\n","from typing import List, Dict, Any, Optional, Union\n","\n","os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n","\n","import tiktoken\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","from langchain.prompts import PromptTemplate\n","from langchain_core.documents import Document\n","from langchain_openai import OpenAI, ChatOpenAI"]},{"cell_type":"markdown","source":["**Basic Utility Functions**"],"metadata":{"id":"Q05rYKWQtavE"}},{"cell_type":"code","source":["def count_tokens(text: str, model: str = \"gpt-3.5-turbo\") -> int:\n","    \"\"\"Count the number of tokens in a text string.\"\"\"\n","    encoder = tiktoken.encoding_for_model(model)\n","    return len(encoder.encode(text))\n","\n","def print_separator():\n","    \"\"\"Print a visual separator.\"\"\"\n","    print(\"\\n\" + \"=\"*50 + \"\\n\")\n","\n","# Create sample text documents for testing\n","sample_docs = [\n","    Document(page_content=\"The Milky Way galaxy contains between 100-400 billion stars and has a diameter of about 100,000 light-years. Our solar system is located in one of the spiral arms, about 27,000 light-years from the galactic center.\",\n","             metadata={\"source\": \"astronomy_textbook\", \"page\": 42}),\n","    Document(page_content=\"Black holes are regions of spacetime where gravitational forces are so strong that nothing, not even light, can escape. The boundary of no escape is called the event horizon. Supermassive black holes are found at the center of most galaxies, including our Milky Way.\",\n","             metadata={\"source\": \"astrophysics_journal\", \"page\": 128}),\n","    Document(page_content=\"Stars are formed in nebulae, which are clouds of gas and dust. When a nebula's core reaches a critical density and temperature, nuclear fusion begins, and a star is born. The color of a star depends on its temperature, with red stars being cooler and blue stars being hotter.\",\n","             metadata={\"source\": \"stellar_formation_guide\", \"page\": 75}),\n","    Document(page_content=\"Exoplanets are planets outside our solar system. As of 2023, over 5,000 exoplanets have been confirmed. They are detected using various methods, including transit photometry and radial velocity measurements. Some exoplanets exist in the 'habitable zone' where conditions might allow for liquid water.\",\n","             metadata={\"source\": \"exoplanet_database\", \"page\": 12}),\n","]\n","\n","# Create a multimodal dataset with text and image descriptions\n","multimodal_data = [\n","    {\n","        \"text\": sample_docs[0].page_content,\n","        \"image_description\": \"Spiral galaxy viewed from above showing the central bulge and spiral arms with stars, gas, and dust. A small indicator shows our solar system's position in one of the outer spiral arms.\",\n","        \"question\": \"Where is our solar system located in the Milky Way galaxy?\",\n","        \"answer\": \"Our solar system is located in one of the spiral arms of the Milky Way galaxy, approximately 27,000 light-years from the galactic center.\"\n","    },\n","    {\n","        \"text\": sample_docs[1].page_content,\n","        \"image_description\": \"Illustration of a black hole showing the event horizon, accretion disk with bright glowing matter swirling around it, and light bending near the event horizon.\",\n","        \"question\": \"What is an event horizon?\",\n","        \"answer\": \"The event horizon is the boundary of a black hole beyond which nothing, not even light, can escape due to the extremely strong gravitational forces.\"\n","    },\n","    {\n","        \"text\": sample_docs[2].page_content,\n","        \"image_description\": \"Image of a nebula with bright stars forming within clouds of colorful gas and dust. Different colored stars are visible: blue, white, yellow, and red.\",\n","        \"question\": \"What determines the color of a star?\",\n","        \"answer\": \"The color of a star depends on its temperature, with red stars being cooler and blue stars being hotter.\"\n","    }\n","]\n","\n","# Complex reasoning questions for advanced templates\n","reasoning_questions = [\n","    {\n","        \"context\": \"\\n\".join([doc.page_content for doc in sample_docs]),\n","        \"question\": \"Based on the information provided, how might the presence of a supermassive black hole affect star formation in a galaxy?\",\n","        \"reasoning\": \"To answer this question, I need to connect information about black holes and star formation from the context. From the context, I know that supermassive black holes are found at the center of most galaxies, including our Milky Way. I also know that stars form in nebulae when gas and dust reach critical density and temperature. A supermassive black hole could affect star formation in several ways: 1) Its strong gravitational pull could compress nearby gas clouds, potentially triggering star formation; 2) The energy released from matter falling into the black hole could heat surrounding gas, preventing it from cooling and condensing to form stars; 3) Black hole jets and radiation could blow away gas needed for star formation. The context doesn't explicitly state these effects, but connecting the information about black holes and star formation allows for these logical inferences.\"\n","    },\n","    {\n","        \"context\": \"\\n\".join([doc.page_content for doc in sample_docs]),\n","        \"question\": \"How might techniques used to detect exoplanets be limited by the properties of different star types?\",\n","        \"reasoning\": \"This requires connecting information about exoplanet detection methods with star properties. The context mentions that exoplanets are detected using transit photometry and radial velocity measurements, and that stars have different colors/temperatures. For transit photometry, which detects planets when they pass in front of their star, limitations could include: 1) With very bright/hot blue stars, the brightness difference caused by a transit might be harder to detect; 2) With red dwarf stars, which are smaller, the relative size of the planet to the star is larger, making transits more noticeable. For radial velocity, which measures a star's 'wobble' due to a planet's gravity: 1) More massive stars would show less wobble from the same planet; 2) Stars with high activity (like many red dwarfs) might have variations that mask the planetary signal. By connecting the properties of stars with the detection methods, I can infer these limitations.\"\n","    }\n","]\n","\n","# Generate a sample complex dataset\n","complex_data = [\n","    {\n","        \"context\": \"Mars has two small moons, Phobos and Deimos. Phobos orbits Mars every 7 hours and 39 minutes at an altitude of 6,000 km. It is gradually spiraling inward at a rate of 1.8 cm per year. Deimos orbits Mars every 30 hours at an altitude of 23,460 km. Unlike Phobos, Deimos is gradually moving away from Mars. Both moons are thought to be captured asteroids.\",\n","        \"question\": \"What will eventually happen to Phobos based on its current orbital trajectory?\",\n","        \"answer\": \"Since Phobos is gradually spiraling inward toward Mars at a rate of 1.8 cm per year, it will eventually either crash into Mars or be torn apart by Mars' gravitational forces when it reaches the Roche limit, forming a planetary ring.\"\n","    },\n","    {\n","        \"context\": \"Europa, a moon of Jupiter, has a surface of solid water ice. Scientists believe there is a liquid water ocean beneath this icy crust, kept warm by tidal heating caused by Jupiter's gravitational pull. The ocean may be up to 100 km deep. Enceladus, a moon of Saturn, also shows evidence of a subsurface ocean, with geysers of water vapor observed erupting from its south pole region.\",\n","        \"question\": \"Compare the mechanisms that might allow for liquid water on Europa and Enceladus.\",\n","        \"answer\": \"Both Europa and Enceladus likely have subsurface liquid water oceans beneath their icy crusts. On Europa, the liquid water is maintained by tidal heating caused by Jupiter's gravitational pull, which prevents the water from freezing despite the cold temperatures far from the Sun. For Enceladus, while not explicitly stated in the context, the presence of geysers erupting from its south pole strongly suggests internal heating, likely also from tidal forces but from Saturn rather than Jupiter. Both moons demonstrate how tidal heating from a massive parent planet can maintain conditions for liquid water far from the Sun's warmth.\"\n","    }\n","]\n","\n","# Section 1: Multi-modal Prompt Templates\n","# ----------------------------------------\n","\n","print(\"Section 1: Multi-modal Prompt Templates\")\n","\n","# Image-aware RAG Template\n","multimodal_template = \"\"\"\n","Use both the text context and images provided to answer the question.\n","\n","TEXT CONTEXT:\n","{text_context}\n","\n","IMAGE CONTEXT:\n","{image_descriptions}\n","\n","QUESTION:\n","{question}\n","\n","When answering:\n","1. Consider information from both text and images\n","2. If images contain relevant information not in the text, include it\n","3. Specify whether your information comes from text or images\n","4. If more visual details would help, mention this\n","\n","ANSWER:\n","\"\"\"\n","\n","# Structured Output with Visual References\n","visual_reference_template = \"\"\"\n","Answer the question using the provided text and image information.\n","\n","TEXT CONTEXT:\n","{text_context}\n","\n","IMAGE DESCRIPTIONS:\n","{image_descriptions}\n","\n","QUESTION:\n","{question}\n","\n","INSTRUCTIONS:\n","- Provide your answer with references to both text [T1, T2, etc.] and images [I1, I2, etc.]\n","- If the answer requires visual information not described, say so clearly\n","- Format tables or structured data appropriately\n","\n","ANSWER:\n","\"\"\"\n","\n","# Test multimodal template\n","example = multimodal_data[0]\n","formatted_multimodal = multimodal_template.format(\n","    text_context=example[\"text\"],\n","    image_descriptions=example[\"image_description\"],\n","    question=example[\"question\"]\n",")\n","\n","print(\"Multimodal Template Example:\")\n","print(formatted_multimodal)\n","print(f\"Tokens: {count_tokens(formatted_multimodal)}\")\n","\n","# Test visual reference template\n","formatted_visual_ref = visual_reference_template.format(\n","    text_context=example[\"text\"],\n","    image_descriptions=example[\"image_description\"],\n","    question=example[\"question\"]\n",")\n","\n","print(\"\\nVisual Reference Template Example:\")\n","print(formatted_visual_ref)\n","print(f\"Tokens: {count_tokens(formatted_visual_ref)}\")\n","\n","# Example of simulating a multimodal retrieval system\n","def multimodal_retrieval_simulation(query, corpus):\n","    \"\"\"\n","    Simulate a multimodal retrieval system that returns\n","    both text and image descriptions.\n","    In a real system, this would use vector search on embeddings.\n","    \"\"\"\n","    # Simple keyword matching for simulation\n","    results = []\n","    for item in corpus:\n","        if any(word in item[\"text\"].lower() for word in query.lower().split()):\n","            results.append({\n","                \"text\": item[\"text\"],\n","                \"image_description\": item[\"image_description\"]\n","            })\n","\n","    # Format results for template\n","    if results:\n","        text_context = \"\\n\\n\".join([r[\"text\"] for r in results])\n","        image_descriptions = \"\\n\\n\".join([f\"Image {i+1}: {r['image_description']}\"\n","                                          for i, r in enumerate(results)])\n","        return {\n","            \"text_context\": text_context,\n","            \"image_descriptions\": image_descriptions\n","        }\n","    else:\n","        return {\n","            \"text_context\": \"No relevant text found.\",\n","            \"image_descriptions\": \"No relevant images found.\"\n","        }\n","\n","# Test the multimodal retrieval\n","query = \"black hole event horizon\"\n","retrieved = multimodal_retrieval_simulation(query, multimodal_data)\n","\n","print(\"\\nMultimodal Retrieval Example:\")\n","print(\"Query:\", query)\n","print(\"Retrieved Text:\", retrieved[\"text_context\"])\n","print(\"Retrieved Images:\", retrieved[\"image_descriptions\"])\n","\n","# Generate a response using the multimodal template\n","if os.environ.get(\"OPENAI_API_KEY\"):\n","    try:\n","        print(\"\\nGenerating response with LLM:\")\n","        llm = ChatOpenAI(temperature=0)\n","        prompt = multimodal_template.format(\n","            text_context=retrieved[\"text_context\"],\n","            image_descriptions=retrieved[\"image_descriptions\"],\n","            question=\"What is the significance of a black hole's event horizon?\"\n","        )\n","        response = llm.invoke(prompt)\n","        print(\"Response:\", response.content)\n","    except Exception as e:\n","        print(f\"Error generating response: {e}\")\n","else:\n","    print(\"\\nOpenAI API key not set - skipping LLM response generation\")\n","\n","print_separator()"],"metadata":{"id":"zsGvT9s_tZ-N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Section 2: Templates for Complex Reasoning Chains**"],"metadata":{"id":"U7dQkHJJuFf1"}},{"cell_type":"code","source":["print(\"Section 2: Templates for Complex Reasoning Chains\")\n","\n","# Chain-of-Thought RAG Template\n","cot_rag_template = \"\"\"\n","Analyze the provided information to answer the question.\n","\n","CONTEXT:\n","{context}\n","\n","QUESTION:\n","{question}\n","\n","REASONING PROCESS:\n","1. Identify key facts and concepts from the context relevant to the question\n","2. Analyze relationships between these elements\n","3. Consider any constraints or conditions mentioned\n","4. Develop logical inferences step by step\n","5. Formulate a well-reasoned answer\n","\n","Provide your complete reasoning process before giving the final answer.\n","\n","ANSWER:\n","\"\"\"\n","\n","# Tree of Thoughts Template\n","tot_template = \"\"\"\n","Explore multiple reasoning paths to answer this question.\n","\n","CONTEXT:\n","{context}\n","\n","QUESTION:\n","{question}\n","\n","SOLUTION APPROACH:\n","1. Path A: Consider first that...\n","   a. Analyze the implications...\n","   b. Evaluate whether this leads to...\n","   c. Determine if this approach is sufficient...\n","\n","2. Path B: Alternatively, consider that...\n","   a. Analyze these implications...\n","   b. Evaluate whether this approach...\n","   c. Determine if this path is better...\n","\n","3. Compare the outcomes of different reasoning paths\n","4. Select the most complete and accurate answer\n","\n","Explicitly show your exploration of different reasoning approaches.\n","\n","ANSWER:\n","\"\"\"\n","\n","# Retrieval-Augmented Verification\n","verification_template = \"\"\"\n","Answer the question and then verify your answer using the provided context.\n","\n","CONTEXT:\n","{context}\n","\n","QUESTION:\n","{question}\n","\n","ANSWER PROCESS:\n","1. First, generate your best answer to the question\n","2. Then, analyze the context for specific information that confirms or contradicts your answer\n","3. Look for potential gaps or assumptions in your initial answer\n","4. Correct any errors or omissions based on the context\n","5. Provide your final, verified answer with appropriate confidence\n","\n","FINAL ANSWER:\n","\"\"\"\n","\n","# Test Chain-of-Thought template\n","example = reasoning_questions[0]\n","formatted_cot = cot_rag_template.format(\n","    context=example[\"context\"],\n","    question=example[\"question\"]\n",")\n","\n","print(\"Chain-of-Thought Template Example:\")\n","print(formatted_cot)\n","print(f\"Tokens: {count_tokens(formatted_cot)}\")\n","\n","# Test Tree of Thoughts template\n","formatted_tot = tot_template.format(\n","    context=example[\"context\"],\n","    question=example[\"question\"]\n",")\n","\n","print(\"\\nTree of Thoughts Template Example:\")\n","print(formatted_tot)\n","print(f\"Tokens: {count_tokens(formatted_tot)}\")\n","\n","# Test Verification template\n","formatted_verification = verification_template.format(\n","    context=example[\"context\"],\n","    question=example[\"question\"]\n",")\n","\n","print(\"\\nVerification Template Example:\")\n","print(formatted_verification)\n","print(f\"Tokens: {count_tokens(formatted_verification)}\")\n","\n","# Compare reasoning templates\n","if os.environ.get(\"OPENAI_API_KEY\"):\n","    try:\n","        print(\"\\nComparing reasoning templates with LLM:\")\n","        llm = ChatOpenAI(temperature=0)\n","\n","        # Use a simpler question for demonstration\n","        simple_q = \"Based on the context, why are some stars red and others blue?\"\n","        simple_ctx = sample_docs[2].page_content\n","\n","        # Standard template\n","        standard_template = \"\"\"\n","        Answer the question based on the context.\n","\n","        CONTEXT:\n","        {context}\n","\n","        QUESTION:\n","        {question}\n","\n","        ANSWER:\n","        \"\"\"\n","\n","        standard_prompt = standard_template.format(context=simple_ctx, question=simple_q)\n","        cot_prompt = cot_rag_template.format(context=simple_ctx, question=simple_q)\n","\n","        standard_response = llm.invoke(standard_prompt).content\n","        cot_response = llm.invoke(cot_prompt).content\n","\n","        print(\"\\nStandard Template Response:\")\n","        print(standard_response)\n","\n","        print(\"\\nChain-of-Thought Template Response:\")\n","        print(cot_response)\n","\n","    except Exception as e:\n","        print(f\"Error comparing templates: {e}\")\n","else:\n","    print(\"\\nOpenAI API key not set - skipping template comparison\")\n","\n","print_separator()"],"metadata":{"id":"HhNZWEKiuFpk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Section 3: Self-Reflective Prompts and Self-Correction**"],"metadata":{"id":"RQq-BLnquPVM"}},{"cell_type":"code","source":["print(\"Section 3: Self-Reflective Prompts and Self-Correction\")\n","\n","# Self-Reflection Template\n","self_reflection_template = \"\"\"\n","Answer the question using the provided information, then reflect on your answer.\n","\n","CONTEXT:\n","{context}\n","\n","QUESTION:\n","{question}\n","\n","INITIAL ANSWER:\n","[Provide your best answer based on the context]\n","\n","REFLECTION:\n","- What assumptions did I make in my answer?\n","- Did I use all relevant information from the context?\n","- Are there alternative interpretations I should consider?\n","- How confident am I in each part of my answer?\n","- What additional information would strengthen my answer?\n","\n","IMPROVED ANSWER:\n","[Provide a refined answer based on your reflection]\n","\"\"\"\n","\n","# Adversarial Self-Critique\n","adversarial_template = \"\"\"\n","You will answer the question in two phases: first as an answer generator,\n","then as a critical reviewer looking for flaws.\n","\n","CONTEXT:\n","{context}\n","\n","QUESTION:\n","{question}\n","\n","PHASE 1 - ANSWER:\n","[Generate your best answer based on the context]\n","\n","PHASE 2 - CRITIQUE:\n","[Now adopt a skeptical perspective]\n","- Identify any unsupported claims in the answer\n","- Find any missing context or nuance\n","- Check if all relevant information was included\n","- Look for potential misinterpretations\n","\n","FINAL ANSWER:\n","[Provide an improved answer addressing the critique]\n","\"\"\"\n","\n","# Test Self-Reflection template\n","example = complex_data[0]\n","formatted_reflection = self_reflection_template.format(\n","    context=example[\"context\"],\n","    question=example[\"question\"]\n",")\n","\n","print(\"Self-Reflection Template Example:\")\n","print(formatted_reflection)\n","print(f\"Tokens: {count_tokens(formatted_reflection)}\")\n","\n","# Test Adversarial Self-Critique template\n","formatted_adversarial = adversarial_template.format(\n","    context=example[\"context\"],\n","    question=example[\"question\"]\n",")\n","\n","print(\"\\nAdversarial Self-Critique Template Example:\")\n","print(formatted_adversarial)\n","print(f\"Tokens: {count_tokens(formatted_adversarial)}\")\n","\n","# Compare self-reflective templates\n","if os.environ.get(\"OPENAI_API_KEY\"):\n","    try:\n","        print(\"\\nComparing self-reflective templates with LLM:\")\n","        llm = ChatOpenAI(temperature=0)\n","\n","        adversarial_prompt = adversarial_template.format(\n","            context=example[\"context\"],\n","            question=example[\"question\"]\n","        )\n","\n","        adversarial_response = llm.invoke(adversarial_prompt).content\n","\n","        print(\"\\nAdversarial Self-Critique Response:\")\n","        print(adversarial_response)\n","\n","    except Exception as e:\n","        print(f\"Error comparing templates: {e}\")\n","else:\n","    print(\"\\nOpenAI API key not set - skipping template comparison\")\n","\n","print_separator()"],"metadata":{"id":"OBmFRidCuPf0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Section 4: Templates for Hybrid Human-AI Workflows**"],"metadata":{"id":"Qz10VreAuXVw"}},{"cell_type":"code","source":["print(\"Section 4: Templates for Hybrid Human-AI Workflows\")\n","\n","# Uncertainty Highlighting Template\n","uncertainty_template = \"\"\"\n","Answer the question based on the provided context.\n","\n","CONTEXT:\n","{context}\n","\n","QUESTION:\n","{question}\n","\n","FORMAT YOUR ANSWER AS FOLLOWS:\n","1. Main answer with high-confidence statements\n","2. [UNCERTAIN: Areas where information is ambiguous or incomplete]\n","3. [MISSING: Key information needed to fully answer the question]\n","4. Suggested follow-up questions for clarification\n","\n","ANSWER:\n","\"\"\"\n","\n","# Feedback-Ready Template\n","feedback_template = \"\"\"\n","Answer the question based on the context. Structure your response to facilitate expert feedback.\n","\n","CONTEXT:\n","{context}\n","\n","QUESTION:\n","{question}\n","\n","ANSWER STRUCTURE:\n","1. Summary (key points in 1-2 sentences)\n","2. Detailed explanation with reasoning\n","   - Point A: [Evidence] → [Conclusion]\n","   - Point B: [Evidence] → [Conclusion]\n","3. Alternative interpretations if applicable\n","4. Confidence assessment (High/Medium/Low) with rationale\n","5. [FEEDBACK REQUESTED: Specific aspects where expert input would be valuable]\n","\n","ANSWER:\n","\"\"\"\n","\n","# Test Uncertainty Highlighting template\n","example = complex_data[1]\n","formatted_uncertainty = uncertainty_template.format(\n","    context=example[\"context\"],\n","    question=example[\"question\"]\n",")\n","\n","print(\"Uncertainty Highlighting Template Example:\")\n","print(formatted_uncertainty)\n","print(f\"Tokens: {count_tokens(formatted_uncertainty)}\")\n","\n","# Test Feedback-Ready template\n","formatted_feedback = feedback_template.format(\n","    context=example[\"context\"],\n","    question=example[\"question\"]\n",")\n","\n","print(\"\\nFeedback-Ready Template Example:\")\n","print(formatted_feedback)\n","print(f\"Tokens: {count_tokens(formatted_feedback)}\")\n","\n","# Demonstrate hybrid workflow\n","if os.environ.get(\"OPENAI_API_KEY\"):\n","    try:\n","        print(\"\\nDemonstrating hybrid human-AI workflow:\")\n","        llm = ChatOpenAI(temperature=0)\n","\n","        # Initial response with uncertainty highlighting\n","        uncertainty_prompt = uncertainty_template.format(\n","            context=example[\"context\"],\n","            question=example[\"question\"]\n","        )\n","\n","        initial_response = llm.invoke(uncertainty_prompt).content\n","\n","        print(\"\\nInitial Response with Uncertainty Highlighting:\")\n","        print(initial_response)\n","\n","        # Simulate human feedback\n","        human_feedback = \"\"\"\n","        Expert feedback: The explanation about tidal heating is good, but you should mention\n","        that the gravitational interactions with other Jovian moons also contribute to Europa's\n","        heating. For Enceladus, the heating mechanism is indeed tidal, involving Saturn's gravity\n","        and orbital resonances with other moons, particularly Dione.\n","        \"\"\"\n","\n","        # Follow-up response incorporating feedback\n","        feedback_prompt = f\"\"\"\n","        You previously provided this answer:\n","\n","        {initial_response}\n","\n","        You've now received this expert feedback:\n","\n","        {human_feedback}\n","\n","        Please update your response to incorporate this feedback.\n","        \"\"\"\n","\n","        updated_response = llm.invoke(feedback_prompt).content\n","\n","        print(\"\\nUpdated Response After Human Feedback:\")\n","        print(updated_response)\n","\n","    except Exception as e:\n","        print(f\"Error in human-AI workflow demo: {e}\")\n","else:\n","    print(\"\\nOpenAI API key not set - skipping human-AI workflow demo\")\n","\n","print_separator()"],"metadata":{"id":"TNHEUCUKuXeF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Section 5: Comparative Analysis of Advanced Templates**"],"metadata":{"id":"KJi-5L8qugLu"}},{"cell_type":"code","source":["print(\"Section 5: Comparative Analysis of Advanced Templates\")\n","\n","# Define template variations for comparison\n","template_variations = {\n","    \"standard\": \"\"\"\n","    Answer the question based on the context.\n","\n","    CONTEXT:\n","    {context}\n","\n","    QUESTION:\n","    {question}\n","\n","    ANSWER:\n","    \"\"\",\n","\n","    \"chain_of_thought\": cot_rag_template,\n","    \"self_reflection\": self_reflection_template,\n","    \"adversarial\": adversarial_template,\n","    \"uncertainty\": uncertainty_template\n","}\n","\n","# Define evaluation criteria\n","evaluation_criteria = [\n","    \"Factual accuracy\",\n","    \"Reasoning depth\",\n","    \"Handling uncertainty\",\n","    \"Identifying assumptions\",\n","    \"Avoiding overconfidence\",\n","    \"Contextual relevance\"\n","]\n","\n","# Mock comparative analysis (would normally use actual LLM outputs)\n","# In a real scenario, these would be determined through human evaluation or automated metrics\n","comparative_scores = {\n","    \"standard\": [0.85, 0.45, 0.30, 0.25, 0.40, 0.80],\n","    \"chain_of_thought\": [0.88, 0.85, 0.55, 0.60, 0.65, 0.85],\n","    \"self_reflection\": [0.90, 0.80, 0.75, 0.85, 0.80, 0.85],\n","    \"adversarial\": [0.92, 0.75, 0.80, 0.90, 0.85, 0.85],\n","    \"uncertainty\": [0.85, 0.70, 0.90, 0.75, 0.90, 0.80]\n","}\n","\n","# Display comparative analysis\n","print(\"Comparative Analysis of Template Effectiveness:\")\n","print(f\"{'Criteria':<25} | {'Standard':<10} | {'CoT':<10} | {'Self-Reflect':<10} | {'Adversarial':<10} | {'Uncertainty':<10}\")\n","print(\"-\" * 80)\n","\n","for i, criterion in enumerate(evaluation_criteria):\n","    scores = [\n","        comparative_scores[\"standard\"][i],\n","        comparative_scores[\"chain_of_thought\"][i],\n","        comparative_scores[\"self_reflection\"][i],\n","        comparative_scores[\"adversarial\"][i],\n","        comparative_scores[\"uncertainty\"][i]\n","    ]\n","    print(f\"{criterion:<25} | {scores[0]:<10.2f} | {scores[1]:<10.2f} | {scores[2]:<10.2f} | {scores[3]:<10.2f} | {scores[4]:<10.2f}\")\n","\n","# Visualize the comparative analysis\n","try:\n","    # Create radar chart\n","    labels = evaluation_criteria\n","    angles = np.linspace(0, 2*np.pi, len(labels), endpoint=False).tolist()\n","    angles += angles[:1]  # Close the polygon\n","\n","    fig, ax = plt.subplots(figsize=(10, 8), subplot_kw=dict(polar=True))\n","\n","    for template_name, scores in comparative_scores.items():\n","        values = scores.copy()\n","        values += values[:1]  # Close the polygon\n","        ax.plot(angles, values, linewidth=2, label=template_name)\n","        ax.fill(angles, values, alpha=0.1)\n","\n","    ax.set_theta_offset(np.pi / 2)\n","    ax.set_theta_direction(-1)\n","    ax.set_thetagrids(np.degrees(angles[:-1]), labels)\n","    ax.set_ylim(0, 1)\n","    ax.set_rlabel_position(0)\n","    ax.set_title(\"Advanced Template Comparison\", fontsize=14, pad=20)\n","    ax.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n","\n","    plt.tight_layout()\n","    plt.show()\n","except Exception as e:\n","    print(f\"Error creating visualization: {e}\")\n","    print(\"To view the visualization, run this notebook in an environment that supports matplotlib.\")\n","\n","print(\"\\nTemplate Strengths Analysis:\")\n","print(\"- Standard templates: Good for straightforward factual questions\")\n","print(\"- Chain-of-Thought: Excels at complex reasoning tasks requiring step-by-step analysis\")\n","print(\"- Self-Reflection: Best for identifying assumptions and handling ambiguity\")\n","print(\"- Adversarial: Strongest for avoiding factual errors and identifying gaps\")\n","print(\"- Uncertainty Highlighting: Optimal for transparently communicating confidence levels\")\n","\n","print_separator()"],"metadata":{"id":"V-PAEhj5ugV7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Section 6: Implementing Advanced Templates in Production**"],"metadata":{"id":"VstIRBUCuo2w"}},{"cell_type":"code","source":["print(\"Section 6: Implementing Advanced Templates in Production\")\n","\n","print(\"Practical Implementation Considerations:\")\n","print(\"\\n1. Template Selection Strategy\")\n","print(\"   Based on query characteristics, select the appropriate template:\")\n","print(\"   - Factual questions → Standard templates\")\n","print(\"   - Complex reasoning → Chain-of-Thought templates\")\n","print(\"   - High-stakes decisions → Self-reflective or Adversarial templates\")\n","print(\"   - Expert collaboration → Uncertainty or Feedback-Ready templates\")\n","print(\"   - Multi-modal questions → Image-aware templates\")\n","\n","# Example template selector function\n","def select_advanced_template(query, context, has_images=False):\n","    \"\"\"\n","    Select the most appropriate template based on query characteristics.\n","    \"\"\"\n","    # Check if query has multi-modal elements\n","    if has_images:\n","        return multimodal_template\n","\n","    # Check if query appears to require complex reasoning\n","    reasoning_indicators = [\"why\", \"how\", \"explain\", \"reason\", \"analyze\",\n","                            \"compare\", \"contrast\", \"evaluate\", \"what if\"]\n","    if any(indicator in query.lower() for indicator in reasoning_indicators):\n","        return cot_rag_template\n","\n","    # Check if query might benefit from uncertainty handling\n","    uncertainty_indicators = [\"possible\", \"might\", \"could\", \"uncertain\",\n","                              \"likelihood\", \"probability\", \"estimate\"]\n","    if any(indicator in query.lower() for indicator in uncertainty_indicators):\n","        return uncertainty_template\n","\n","    # Check if query is sensitive or high-stakes\n","    sensitive_topics = [\"health\", \"medical\", \"legal\", \"financial\",\n","                         \"safety\", \"critical\", \"important decision\"]\n","    if any(topic in query.lower() or topic in context.lower() for topic in sensitive_topics):\n","        return adversarial_template\n","\n","    # Default to standard template\n","    return template_variations[\"standard\"]\n","\n","# Test template selection\n","test_queries = [\n","    \"What is the diameter of the Milky Way galaxy?\",\n","    \"Why might supermassive black holes affect star formation in galaxies?\",\n","    \"What is the likelihood of finding habitable exoplanets around red dwarf stars?\",\n","    \"What medical conditions might arise from long-term space travel?\",\n","    \"Compare the star formation process in different nebula types.\"\n","]\n","\n","print(\"\\n2. Template Selection Examples:\")\n","for query in test_queries:\n","    template = select_advanced_template(query, sample_docs[0].page_content)\n","    template_name = \"Standard\"\n","    for name, tmpl in template_variations.items():\n","        if template == tmpl:\n","            template_name = name\n","    print(f\"Query: '{query}'\")\n","    print(f\"Selected template: {template_name}\")\n","    print()\n","\n","print(\"\\n3. Token Usage Management\")\n","print(\"   Advanced templates consume more tokens but may provide better results.\")\n","print(\"   Token usage comparison:\")\n","\n","# Compare token usage\n","test_context = sample_docs[0].page_content\n","test_question = \"Explain how the position of our solar system in the Milky Way affects our astronomical observations.\"\n","\n","token_usage = {}\n","for name, template in template_variations.items():\n","    formatted = template.format(context=test_context, question=test_question)\n","    token_count = count_tokens(formatted)\n","    token_usage[name] = token_count\n","\n","# Sort by token usage\n","sorted_usage = sorted(token_usage.items(), key=lambda x: x[1])\n","for name, count in sorted_usage:\n","    print(f\"   - {name}: {count} tokens\")\n","\n","print(\"\\n4. Template Chaining Strategy\")\n","print(\"   For complex RAG applications, chain multiple templates:\")\n","print(\"   - First use Chain-of-Thought to generate an initial answer\")\n","print(\"   - Then use Self-Reflection or Adversarial to refine the answer\")\n","print(\"   - Finally use Uncertainty Highlighting for presentation\")\n","\n","print(\"\\n5. Monitoring and Evaluation\")\n","print(\"   In production, continuously monitor template performance:\")\n","print(\"   - Track factual accuracy, reasoning quality, and user satisfaction\")\n","print(\"   - A/B test template variations on similar queries\")\n","print(\"   - Collect human feedback on different template outputs\")\n","print(\"   - Adjust template selection strategy based on performance data\")\n","\n","print_separator()"],"metadata":{"id":"oDjcTDhuupAp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Section 7: Case Studies and Real-World Applications**"],"metadata":{"id":"Q__QhnVmuxB1"}},{"cell_type":"code","source":["print(\"Section 7: Case Studies and Real-World Applications\")\n","\n","print(\"Case Study 1: Scientific Research Assistant\")\n","print(\"\\nChallenge: Researchers need accurate information from scientific papers with proper source attribution and uncertainty communication.\")\n","print(\"\\nSolution: Chain-of-Thought + Uncertainty Highlighting template\")\n","\n","scientific_template = \"\"\"\n","Analyze the scientific information to answer the research question.\n","\n","SOURCES:\n","{context}\n","\n","RESEARCH QUESTION:\n","{question}\n","\n","ANALYSIS APPROACH:\n","1. Identify relevant findings and methodologies from the sources\n","2. Evaluate the strength of evidence for each finding\n","3. Analyze any conflicting results or interpretations\n","4. Consider methodological limitations that affect conclusions\n","5. Synthesize a comprehensive answer\n","\n","FORMAT:\n","- Main findings: [High confidence statements with citations]\n","- Interpretations: Step-by-step reasoning connecting findings to conclusions\n","- Limitations: [UNCERTAINTY: Areas where evidence is limited or conflicting]\n","- Research gaps: [MISSING: Important information not addressed in the sources]\n","- Future directions: Suggestions for further investigation\n","\n","ANSWER:\n","\"\"\"\n","\n","print(\"Example scientific research template application:\")\n","print(\"Query: 'What is the current consensus on exoplanet habitability indicators?'\")\n","print(\"Uses Chain-of-Thought reasoning to analyze conflicting research findings\")\n","print(\"Highlights uncertainty in specific areas where evidence is limited\")\n","print(\"Explicitly notes information gaps to guide further research\")\n","\n","print(\"\\nCase Study 2: Medical Decision Support\")\n","print(\"\\nChallenge: Clinicians need accurate medical information with clear indication of confidence levels and potential alternatives.\")\n","print(\"\\nSolution: Adversarial Self-Critique + Feedback-Ready template\")\n","\n","medical_template = \"\"\"\n","Analyze the medical information to address the clinical question.\n","\n","MEDICAL SOURCES:\n","{context}\n","\n","CLINICAL QUESTION:\n","{question}\n","\n","TWO-PHASE ANALYSIS:\n","\n","PHASE 1 - INITIAL ASSESSMENT:\n","1. Relevant clinical findings from the sources\n","2. Evidence-based interpretations\n","3. Potential diagnostic or treatment considerations\n","\n","PHASE 2 - CRITICAL REVIEW:\n","1. Identify evidence limitations or contradictions\n","2. Consider alternative interpretations\n","3. Assess generalizability to the specific clinical scenario\n","4. Identify potential risks or contraindications\n","\n","FORMAT:\n","- Summary: Brief overview of key points\n","- Evidence: [Source X] Specific findings → Clinical implications\n","- Confidence level: (High/Moderate/Low) with explanation\n","- Alternatives: Important differential considerations\n","- [CONSULTATION RECOMMENDED]: Specific aspects requiring clinical judgment\n","\n","RESPONSE:\n","\"\"\"\n","\n","print(\"Example medical decision support template application:\")\n","print(\"Query: 'What are the latest treatment approaches for resistant hypertension?'\")\n","print(\"Uses adversarial approach to critically evaluate treatment options\")\n","print(\"Explicitly labels confidence levels for different recommendations\")\n","print(\"Highlights areas where physician judgment is particularly important\")\n","\n","print(\"\\nCase Study 3: Legal Research Assistant\")\n","print(\"\\nChallenge: Legal professionals need accurate citation of relevant statutes and precedents with nuanced interpretation.\")\n","print(\"\\nSolution: Tree of Thoughts + Attribution template\")\n","\n","legal_template = \"\"\"\n","Analyze the legal information to address the question.\n","\n","LEGAL SOURCES:\n","{context}\n","\n","LEGAL QUESTION:\n","{question}\n","\n","ANALYSIS PATHS:\n","\n","PATH A - STATUTORY INTERPRETATION:\n","1. Identify relevant statutes and regulations\n","2. Analyze the plain language meaning\n","3. Consider legislative intent if available\n","4. Evaluate applicability to the specific scenario\n","\n","PATH B - CASE LAW ANALYSIS:\n","1. Identify relevant precedents\n","2. Extract key holdings and principles\n","3. Analyze factual similarities and differences\n","4. Consider jurisdictional limitations\n","\n","PATH C - DOCTRINAL APPROACH:\n","1. Identify legal doctrines at issue\n","2. Analyze how courts have applied these doctrines\n","3. Consider scholarly interpretations\n","4. Evaluate evolution of doctrine over time\n","\n","FORMAT:\n","- Summary conclusion based on most applicable analysis path\n","- Citations in proper legal format [Case/Statute X]\n","- Explicit reasoning connecting authorities to conclusion\n","- Alternative interpretations where authorities conflict\n","- Limitations: Jurisdictional constraints or distinguishing factors\n","\n","LEGAL ANALYSIS:\n","\"\"\"\n","\n","print(\"Example legal research template application:\")\n","print(\"Query: 'What are the requirements for establishing fair use in copyright infringement cases?'\")\n","print(\"Explores multiple analytical approaches (statutory, case law, and doctrinal)\")\n","print(\"Provides precise legal citations in proper format\")\n","print(\"Acknowledges jurisdictional limitations and conflicting precedents\")\n","\n","print(\"\\nCase Study 4: Educational Content Creation\")\n","print(\"\\nChallenge: Educators need accurate explanations at appropriate levels with clear reasoning and learning scaffolds.\")\n","print(\"\\nSolution: Chain-of-Thought + Multimodal template\")\n","\n","educational_template = \"\"\"\n","Create educational content to answer the student's question.\n","\n","SUBJECT MATERIAL:\n","{context}\n","\n","STUDENT QUESTION:\n","{question}\n","\n","EDUCATIONAL LEVEL:\n","{educational_level}\n","\n","LEARNING APPROACH:\n","1. Start with core concepts at the appropriate educational level\n","2. Provide a clear step-by-step explanation of the reasoning\n","3. Connect to visual references where applicable\n","4. Include analogies or examples to illustrate abstract concepts\n","5. Anticipate common misconceptions and address them\n","\n","FORMAT YOUR RESPONSE:\n","- Core Concept: Brief explanation of the fundamental idea\n","- Step-by-Step Reasoning: Clear logical progression\n","- Visual References: Refer to [Image X] where helpful\n","- Practical Example: Concrete application of the concept\n","- Check Understanding: Simple question to verify comprehension\n","\n","EDUCATIONAL RESPONSE:\n","\"\"\"\n","\n","print(\"Example educational template application:\")\n","print(\"Query: 'How do black holes affect spacetime?'\")\n","print(\"Educational level: High school physics\")\n","print(\"Provides step-by-step reasoning with appropriate analogies\")\n","print(\"References relevant diagrams and visual representations\")\n","print(\"Anticipates and addresses common misconceptions\")\n","\n","print_separator()"],"metadata":{"id":"IDNeXv5cuxKj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Section 8: Building a Comprehensive Advanced Template System**"],"metadata":{"id":"LBxUp57NvFRJ"}},{"cell_type":"code","source":["print(\"Section 8: Building a Comprehensive Advanced Template System\")\n","\n","class AdvancedTemplateSystem:\n","    \"\"\"A complete system for managing and deploying advanced RAG templates.\"\"\"\n","\n","    def __init__(self):\n","        # Initialize template library\n","        self.templates = {\n","            \"standard\": template_variations[\"standard\"],\n","            \"chain_of_thought\": cot_rag_template,\n","            \"tree_of_thoughts\": tot_template,\n","            \"verification\": verification_template,\n","            \"self_reflection\": self_reflection_template,\n","            \"adversarial\": adversarial_template,\n","            \"multimodal\": multimodal_template,\n","            \"uncertainty\": uncertainty_template,\n","            \"feedback_ready\": feedback_template,\n","            \"scientific\": scientific_template,\n","            \"medical\": medical_template,\n","            \"legal\": legal_template,\n","            \"educational\": educational_template\n","        }\n","\n","        # Template categories for organization\n","        self.categories = {\n","            \"reasoning\": [\"chain_of_thought\", \"tree_of_thoughts\", \"verification\"],\n","            \"reflective\": [\"self_reflection\", \"adversarial\"],\n","            \"domain_specific\": [\"scientific\", \"medical\", \"legal\", \"educational\"],\n","            \"interactive\": [\"feedback_ready\", \"uncertainty\"],\n","            \"multimodal\": [\"multimodal\"]\n","        }\n","\n","    def get_template(self, name):\n","        \"\"\"Get a template by name.\"\"\"\n","        return self.templates.get(name, self.templates[\"standard\"])\n","\n","    def list_templates(self, category=None):\n","        \"\"\"List available templates, optionally filtered by category.\"\"\"\n","        if category:\n","            return [name for name in self.templates if name in self.categories.get(category, [])]\n","        return list(self.templates.keys())\n","\n","    def analyze_query(self, query, context=None):\n","        \"\"\"Analyze query characteristics to recommend template.\"\"\"\n","        features = {\n","            \"reasoning_required\": False,\n","            \"uncertainty_present\": False,\n","            \"domain_specific\": None,\n","            \"multimodal_elements\": False,\n","            \"complexity_level\": \"low\"\n","        }\n","\n","        # Check for reasoning indicators\n","        reasoning_terms = [\"why\", \"how\", \"explain\", \"reason\", \"analyze\", \"compare\", \"evaluate\"]\n","        if any(term in query.lower() for term in reasoning_terms):\n","            features[\"reasoning_required\"] = True\n","            features[\"complexity_level\"] = \"medium\"\n","\n","        # Check for uncertainty indicators\n","        uncertainty_terms = [\"possible\", \"might\", \"could\", \"uncertain\", \"probability\"]\n","        if any(term in query.lower() for term in uncertainty_terms):\n","            features[\"uncertainty_present\"] = True\n","\n","        # Check for domain indicators\n","        domains = {\n","            \"scientific\": [\"research\", \"study\", \"experiment\", \"hypothesis\", \"theory\", \"scientific\"],\n","            \"medical\": [\"patient\", \"treatment\", \"diagnosis\", \"medical\", \"clinical\", \"symptoms\"],\n","            \"legal\": [\"law\", \"legal\", \"regulation\", \"statute\", \"court\", \"case\", \"precedent\"],\n","            \"educational\": [\"learn\", \"teach\", \"student\", \"education\", \"concept\", \"understand\"]\n","        }\n","\n","        for domain, indicators in domains.items():\n","            if any(term in query.lower() for term in indicators):\n","                features[\"domain_specific\"] = domain\n","                break\n","\n","        # Check for multimodal indicators\n","        multimodal_terms = [\"image\", \"picture\", \"diagram\", \"graph\", \"figure\", \"visual\"]\n","        if any(term in query.lower() for term in multimodal_terms):\n","            features[\"multimodal_elements\"] = True\n","\n","        # Assess complexity\n","        if len(query.split()) > 15 or \",\" in query or \"and\" in query:\n","            features[\"complexity_level\"] = \"high\"\n","\n","        return features\n","\n","    def recommend_template(self, query, context=None, has_images=False):\n","        \"\"\"Recommend the most appropriate template based on query analysis.\"\"\"\n","        features = self.analyze_query(query, context)\n","\n","        # Check for domain-specific templates first\n","        if features[\"domain_specific\"]:\n","            domain_template = features[\"domain_specific\"]\n","            if domain_template in self.templates:\n","                return domain_template\n","\n","        # Check for multimodal needs\n","        if features[\"multimodal_elements\"] or has_images:\n","            return \"multimodal\"\n","\n","        # High complexity queries\n","        if features[\"complexity_level\"] == \"high\":\n","            if features[\"reasoning_required\"]:\n","                return \"tree_of_thoughts\"\n","            else:\n","                return \"verification\"\n","\n","        # Medium complexity queries\n","        if features[\"complexity_level\"] == \"medium\":\n","            if features[\"reasoning_required\"]:\n","                return \"chain_of_thought\"\n","            elif features[\"uncertainty_present\"]:\n","                return \"uncertainty\"\n","            else:\n","                return \"self_reflection\"\n","\n","        # Default to standard for simple queries\n","        return \"standard\"\n","\n","    def format_prompt(self, template_name, **kwargs):\n","        \"\"\"Format a prompt using the specified template and variables.\"\"\"\n","        template = self.get_template(template_name)\n","        formatted = template.format(**kwargs)\n","\n","        # Print token usage for monitoring\n","        token_count = count_tokens(formatted)\n","        print(f\"Using template '{template_name}' ({token_count} tokens)\")\n","\n","        return formatted\n","\n","    def generate_response(self, query, context, llm=None, template_name=None, **kwargs):\n","        \"\"\"Generate a response using the appropriate template.\"\"\"\n","        # If no template specified, recommend one\n","        if not template_name:\n","            template_name = self.recommend_template(query, context)\n","\n","        # Format the prompt\n","        prompt = self.format_prompt(\n","            template_name,\n","            context=context,\n","            question=query,\n","            **kwargs\n","        )\n","\n","        # Generate response if LLM provided\n","        if llm:\n","            try:\n","                response = llm.invoke(prompt)\n","                return {\n","                    \"template_used\": template_name,\n","                    \"prompt\": prompt,\n","                    \"response\": response.content,\n","                    \"token_count\": count_tokens(prompt)\n","                }\n","            except Exception as e:\n","                return {\n","                    \"error\": str(e),\n","                    \"template_used\": template_name,\n","                    \"prompt\": prompt\n","                }\n","        else:\n","            # Return the formatted prompt if no LLM\n","            return {\n","                \"template_used\": template_name,\n","                \"prompt\": prompt,\n","                \"token_count\": count_tokens(prompt)\n","            }\n","\n","# Create the template system\n","template_system = AdvancedTemplateSystem()\n","\n","# Demonstrate template recommendations\n","print(\"Template Recommendation Examples:\")\n","test_queries = [\n","    \"What is the diameter of the Milky Way galaxy?\",\n","    \"Why might supermassive black holes affect star formation in galaxies?\",\n","    \"What is the likelihood of finding habitable exoplanets around red dwarf stars?\",\n","    \"What treatments are recommended for patients with resistant hypertension?\",\n","    \"Can you explain how black holes bend spacetime using the diagram?\",\n","    \"What legal precedents establish the fair use doctrine in copyright law?\"\n","]\n","\n","for query in test_queries:\n","    recommended = template_system.recommend_template(query)\n","    features = template_system.analyze_query(query)\n","    print(f\"Query: '{query}'\")\n","    print(f\"Features: {features}\")\n","    print(f\"Recommended template: {recommended}\")\n","    print()\n","\n","# Demonstrate template usage\n","example_query = \"How do stars form and why do they have different colors?\"\n","example_context = sample_docs[2].page_content\n","\n","result = template_system.generate_response(\n","    example_query,\n","    example_context,\n","    template_name=\"chain_of_thought\"\n",")\n","\n","print(\"\\nGenerated Chain-of-Thought Prompt:\")\n","print(result[\"prompt\"])\n","print(f\"Token count: {result['token_count']}\")\n","\n","# Demonstrate with LLM if available\n","if os.environ.get(\"OPENAI_API_KEY\"):\n","    try:\n","        print(\"\\nGenerating response with LLM:\")\n","        llm = ChatOpenAI(temperature=0)\n","\n","        result_with_llm = template_system.generate_response(\n","            example_query,\n","            example_context,\n","            llm=llm\n","        )\n","\n","        print(f\"Template used: {result_with_llm['template_used']}\")\n","        print(f\"Response: {result_with_llm['response']}\")\n","\n","    except Exception as e:\n","        print(f\"Error generating LLM response: {e}\")\n","else:\n","    print(\"\\nOpenAI API key not set - skipping LLM response generation\")\n","\n","print_separator()\n","\n","print(\"Building an advanced template system provides:\")\n","print(\"1. Consistency across different query types and domains\")\n","print(\"2. Automatic selection of appropriate templates\")\n","print(\"3. Centralized management of template variations\")\n","print(\"4. Easier monitoring of token usage and performance\")\n","print(\"5. Simplified integration with RAG pipelines\")\n","\n","print_separator()"],"metadata":{"id":"zxuBZph5vFZ1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Section 9: Best Practices and Future Directions**"],"metadata":{"id":"_vCjMhiJvPJx"}},{"cell_type":"code","source":["print(\"Section 9: Best Practices and Future Directions\")\n","\n","print(\"Best Practices for Advanced Templates:\")\n","print(\"\\n1. Template Documentation\")\n","print(\"   - Maintain clear documentation for each template\")\n","print(\"   - Record the purpose, strengths, and limitations\")\n","print(\"   - Document token usage patterns and optimization notes\")\n","print(\"   - Include example queries where the template excels\")\n","\n","print(\"\\n2. Performance Monitoring\")\n","print(\"   - Track template performance across different query types\")\n","print(\"   - Monitor token usage, response time, and quality metrics\")\n","print(\"   - Collect user feedback on response quality\")\n","print(\"   - Regularly update templates based on performance data\")\n","\n","print(\"\\n3. Template Versioning\")\n","print(\"   - Maintain version history for all templates\")\n","print(\"   - Document changes between versions\")\n","print(\"   - Test new versions before deployment\")\n","print(\"   - Support rollback to previous versions if needed\")\n","\n","print(\"\\n4. Specialized Template Development\")\n","print(\"   - Create domain-specific templates for key use cases\")\n","print(\"   - Customize templates for different user personas\")\n","print(\"   - Develop templates optimized for different context lengths\")\n","print(\"   - Build templates for specific reasoning patterns\")\n","\n","print(\"\\n5. Hybrid Approaches\")\n","print(\"   - Use template chaining for complex queries\")\n","print(\"   - Combine automatic and manual template selection\")\n","print(\"   - Integrate human feedback loops for continuous improvement\")\n","print(\"   - Develop templates that facilitate human-AI collaboration\")\n","\n","print(\"\\nFuture Directions in Advanced Prompting:\")\n","\n","print(\"\\n1. Dynamic Template Generation\")\n","print(\"   - AI-generated templates customized for specific queries\")\n","print(\"   - Templates that adapt based on user interaction patterns\")\n","print(\"   - Self-optimizing templates that evolve based on performance\")\n","\n","print(\"\\n2. Multi-step Prompting Frameworks\")\n","print(\"   - Frameworks for breaking complex tasks into multiple prompts\")\n","print(\"   - Pipelines that combine different template types\")\n","print(\"   - Meta-prompts that guide the selection of sub-prompts\")\n","\n","print(\"\\n3. Personalized Templates\")\n","print(\"   - Templates adapted to user expertise levels\")\n","print(\"   - Customization based on user preferences\")\n","print(\"   - Domain-specific variations for different industries\")\n","\n","print(\"\\n4. Enhanced Multi-modal Integration\")\n","print(\"   - Templates for integrating multiple data modalities\")\n","print(\"   - Vision-language-retrieval coordination templates\")\n","print(\"   - Templates for generating multimodal outputs\")\n","\n","print(\"\\n5. Reasoning-Enhanced Templates\")\n","print(\"   - Templates with deeper cognitive scaffolding\")\n","print(\"   - Built-in logical validation mechanisms\")\n","print(\"   - Templates that guide formal reasoning patterns\")\n","\n","print_separator()\n","\n","print(\"Notebook completed!\")\n","\n","# Key Takeaways:\n","# 1. Advanced templates enable more sophisticated RAG capabilities like multi-modal integration and complex reasoning\n","# 2. Self-reflective prompts and adversarial approaches can significantly improve response quality\n","# 3. Domain-specific templates provide superior performance for specialized applications\n","# 4. Building a comprehensive template system simplifies management and optimization\n","# 5. Future developments will likely focus on dynamic, personalized, and multi-step prompting frameworks"],"metadata":{"id":"ZZJ5n_iJvPR0"},"execution_count":null,"outputs":[]}]}