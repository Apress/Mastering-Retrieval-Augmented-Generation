{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP6GgL4d5j4YViVZGHCV5XL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Setup and Installation**"],"metadata":{"id":"zgiNox9fECQf"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Q9YEedLD4D-"},"outputs":[],"source":["!pip install -q langchain langchain-openai chromadb pydantic sentence-transformers datasets numpy scikit-learn pandas langchain-community\n","\n","import os\n","import re\n","import json\n","import random\n","import numpy as np\n","from typing import List, Dict, Any, Optional, Union\n","from pydantic import BaseModel, Field\n","\n","# Configure OpenAI API key (replace with your own)\n","os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n","\n","from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n","from langchain_community.vectorstores import Chroma\n","from langchain.schema import Document\n","from langchain.prompts import ChatPromptTemplate\n","from langchain.output_parsers import PydanticOutputParser, CommaSeparatedListOutputParser\n","\n","# Initialize our LLM\n","llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n","\n","print(\"üöÄ Notebook environment setup complete!\")"]},{"cell_type":"markdown","source":["**Creating a sample document collection for our examples**"],"metadata":{"id":"xnvTzH_LKf5P"}},{"cell_type":"code","source":["def create_sample_kb():\n","    \"\"\"Create a sample knowledge base with documents about programming.\"\"\"\n","    docs = [\n","        Document(page_content=\"Python is a high-level, interpreted programming language known for its readability and simplicity. It supports multiple programming paradigms including procedural, object-oriented, and functional programming.\",\n","                 metadata={\"source\": \"programming/python.txt\", \"language\": \"python\", \"category\": \"language_overview\"}),\n","        Document(page_content=\"JavaScript is a scripting language that enables interactive web pages. It is an essential part of web applications and all modern browsers have a dedicated JavaScript engine to execute it.\",\n","                 metadata={\"source\": \"programming/javascript.txt\", \"language\": \"javascript\", \"category\": \"language_overview\"}),\n","        Document(page_content=\"Python lists are mutable sequences, typically used to store collections of homogeneous items. Lists can be indexed, sliced, and modified. Common operations include append(), extend(), insert(), remove(), and pop().\",\n","                 metadata={\"source\": \"programming/python_lists.txt\", \"language\": \"python\", \"category\": \"data_structures\"}),\n","        Document(page_content=\"JavaScript arrays are high-level, list-like objects with additional features. They can be manipulated using methods like push(), pop(), shift(), and unshift(). Array methods like map(), filter(), and reduce() enable functional programming patterns.\",\n","                 metadata={\"source\": \"programming/javascript_arrays.txt\", \"language\": \"javascript\", \"category\": \"data_structures\"}),\n","        Document(page_content=\"Python functions are defined using the def keyword, followed by a function name and parameters. They can include optional type hints, default parameters, variable-length arguments, and return values.\",\n","                 metadata={\"source\": \"programming/python_functions.txt\", \"language\": \"python\", \"category\": \"functions\"}),\n","        Document(page_content=\"JavaScript functions are first-class objects, meaning they can be passed as arguments, returned from other functions, and assigned to variables. They can be declared using function declarations, function expressions, or arrow functions.\",\n","                 metadata={\"source\": \"programming/javascript_functions.txt\", \"language\": \"javascript\", \"category\": \"functions\"}),\n","        Document(page_content=\"Python's exception handling uses try, except, else, and finally blocks. Specific exception types can be caught and handled separately. Custom exceptions can be created by subclassing the Exception class.\",\n","                 metadata={\"source\": \"programming/python_exceptions.txt\", \"language\": \"python\", \"category\": \"error_handling\"}),\n","        Document(page_content=\"JavaScript error handling utilizes try-catch-finally statements. The Error object and its subtypes (SyntaxError, TypeError, etc.) provide information about the error. Custom errors can be created by extending the Error class.\",\n","                 metadata={\"source\": \"programming/javascript_errors.txt\", \"language\": \"javascript\", \"category\": \"error_handling\"}),\n","    ]\n","\n","    # Create embeddings and vectorstore\n","    embeddings = OpenAIEmbeddings()\n","    vectorstore = Chroma.from_documents(documents=docs, embedding=embeddings)\n","    return vectorstore, docs, embeddings\n","\n","# Initialize our sample knowledge base\n","vectorstore, sample_docs, embeddings = create_sample_kb()\n","retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n","\n","print(\"üìö Sample knowledge base created with programming language documents\")"],"metadata":{"id":"1SCc7rhyKgB9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**10.5.1 Prompt Engineering with Examples**"],"metadata":{"id":"QKKHfGAzKqFG"}},{"cell_type":"code","source":["# Few-shot prompt engineering examples\n","examples = [\n","    {\n","        \"query\": \"How do I create a list in Python?\",\n","        \"improved_query\": \"What are Python lists, their syntax, and common operations for creating and manipulating them?\"\n","    },\n","    {\n","        \"query\": \"Tell me about JavaScript functions\",\n","        \"improved_query\": \"What are JavaScript functions, their types (declarations, expressions, arrow functions), and how are they used as first-class objects?\"\n","    },\n","    {\n","        \"query\": \"Error handling\",\n","        \"improved_query\": \"What are the methods and syntax for error handling and exception management in programming languages?\"\n","    }\n","]\n","\n","# Create a few-shot query improvement prompt\n","few_shot_template = \"\"\"You are an expert query optimizer for a retrieval system focused on programming topics.\n","Your task is to improve user queries to maximize the relevance of retrieved information.\n","\n","Here are some examples of how to improve queries:\n","\n","Query: {example1_query}\n","Improved Query: {example1_improved}\n","\n","Query: {example2_query}\n","Improved Query: {example2_improved}\n","\n","Query: {example3_query}\n","Improved Query: {example3_improved}\n","\n","Now, please improve the following query:\n","Query: {query}\n","\n","Improved Query:\"\"\"\n","\n","def improve_query_with_examples(query):\n","    \"\"\"Improve a user query using few-shot learning examples\"\"\"\n","    prompt = few_shot_template.format(\n","        example1_query=examples[0][\"query\"],\n","        example1_improved=examples[0][\"improved_query\"],\n","        example2_query=examples[1][\"query\"],\n","        example2_improved=examples[1][\"improved_query\"],\n","        example3_query=examples[2][\"query\"],\n","        example3_improved=examples[2][\"improved_query\"],\n","        query=query\n","    )\n","\n","    improved_query = llm.invoke(prompt).content\n","    return improved_query\n","\n","# Test the simple few-shot approach\n","print(\"\\nüìù Testing few-shot query improvement:\")\n","test_queries = [\n","    \"how to use arrays in JavaScript\",\n","    \"what is exception handling\"\n","]\n","\n","for query in test_queries:\n","    improved = improve_query_with_examples(query)\n","    print(f\"Original: {query}\")\n","    print(f\"Improved: {improved}\\n\")"],"metadata":{"id":"RnEG2snoKqMr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**10.5.2 Handling Edge Cases in Query Generation**"],"metadata":{"id":"Zc1Lkf1nK0tq"}},{"cell_type":"code","source":["def query_generation_with_fallbacks(user_input, max_retries=3):\n","    \"\"\"Generate a search query with fallback mechanisms\"\"\"\n","\n","    # Initial prompt for query generation\n","    prompt_template = \"\"\"Based on the user's input, generate a clear search query that would help retrieve relevant information.\n","The query should be concise and focused on the core information need.\n","\n","User Input: {input}\n","\n","Search Query:\"\"\"\n","\n","    # Try to generate a query\n","    for attempt in range(max_retries):\n","        try:\n","            # Adjust temperature for each retry - getting more creative if earlier attempts failed\n","            temperature = 0.2 * (attempt + 1)  # Start at 0.2, then 0.4, then 0.6\n","            current_llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=temperature)\n","\n","            # Generate query\n","            query = current_llm.invoke(prompt_template.format(input=user_input)).content\n","\n","            # Validate the query is non-empty and substantive (at least 3 words)\n","            if query and len(query.split()) >= 3:\n","                return query, attempt, False\n","\n","            # If validation fails, trigger fallback\n","            raise ValueError(\"Generated query too short or empty\")\n","\n","        except Exception as e:\n","            print(f\"Attempt {attempt+1} failed: {str(e)}\")\n","\n","            if attempt == max_retries - 1:\n","                # Final fallback: extract keywords from the user input\n","                fallback_query = extract_keywords_fallback(user_input)\n","                return fallback_query, attempt, True\n","\n","    # Should never reach here due to final fallback, but just in case\n","    return user_input, max_retries, True\n","\n","def extract_keywords_fallback(text):\n","    \"\"\"Extract key nouns and entities as a fallback query mechanism\"\"\"\n","    # For a production system, you might use NLP libraries like spaCy\n","    # This is a simplified version\n","\n","    # Remove common filler words\n","    stopwords = [\"the\", \"a\", \"an\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\",\n","                \"being\", \"to\", \"of\", \"and\", \"or\", \"not\", \"for\", \"with\", \"by\", \"about\"]\n","\n","    # Lowercase and tokenize\n","    tokens = re.findall(r'\\b\\w+\\b', text.lower())\n","\n","    # Remove stopwords and keep words with 3+ chars\n","    keywords = [word for word in tokens if word not in stopwords and len(word) >= 3]\n","\n","    # Take the most frequent 3-5 keywords\n","    if len(keywords) > 5:\n","        # Count frequencies (a simple approach)\n","        from collections import Counter\n","        keyword_counts = Counter(keywords)\n","        keywords = [word for word, _ in keyword_counts.most_common(5)]\n","\n","    return \" \".join(keywords)\n","\n","# Test with problematic inputs\n","print(\"\\n‚ö†Ô∏è Testing query generation with problematic inputs:\")\n","problematic_inputs = [\n","    \"???\",\n","    \"I'm not sure what I'm looking for, maybe something about programming?\"\n","]\n","\n","for input_text in problematic_inputs:\n","    query, attempts, used_fallback = query_generation_with_fallbacks(input_text)\n","    print(f\"Input: {input_text}\")\n","    print(f\"Generated Query: {query}\")\n","    print(f\"Attempts: {attempts + 1}, Used Fallback: {used_fallback}\\n\")"],"metadata":{"id":"v-agbqs0K02P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**10.5.3 Multi-Query and Multi-Retriever Architectures**"],"metadata":{"id":"C2dg0hW1K_GO"}},{"cell_type":"code","source":["# Multi-query generation\n","def generate_query_variations(query, n=3):\n","    \"\"\"Generate multiple variations of a query to improve retrieval coverage\"\"\"\n","\n","    prompt = f\"\"\"Generate {n} different versions of the following search query.\n","Each version should focus on a different aspect or use different terminology,\n","but all should aim to retrieve similar information.\n","\n","Original query: {query}\n","\n","Generate exactly {n} alternative queries, numbered 1-{n}.\n","1.\"\"\"\n","\n","    response = llm.invoke(prompt).content\n","\n","    # Parse the numbered list of queries\n","    variation_pattern = r\"\\d+\\.\\s*(.*?)(?=\\d+\\.|$)\"\n","    variations = re.findall(variation_pattern, response, re.DOTALL)\n","\n","    # Clean up the variations\n","    variations = [v.strip() for v in variations]\n","\n","    # Ensure we have the requested number of variations\n","    while len(variations) < n:\n","        variations.append(query)  # Fall back to original if parsing failed\n","\n","    # Limit to requested number\n","    variations = variations[:n]\n","\n","    return variations\n","\n","# Simple Multi-Query Retriever implementation\n","def retrieve_with_variations(query, base_retriever, n_variations=2):\n","    \"\"\"Retrieve documents using the original query and its variations\"\"\"\n","    # Generate variations\n","    variations = generate_query_variations(query, n=n_variations)\n","\n","    print(f\"Original: {query}\")\n","    for i, var in enumerate(variations, 1):\n","        print(f\"Variation {i}: {var}\")\n","\n","    # Get results from each query\n","    all_docs = []\n","\n","    # Add results from original query\n","    original_docs = base_retriever.get_relevant_documents(query)\n","    all_docs.extend(original_docs)\n","\n","    # Add results from variations\n","    for var in variations:\n","        var_docs = base_retriever.get_relevant_documents(var)\n","        all_docs.extend(var_docs)\n","\n","    # Deduplicate results\n","    seen_contents = set()\n","    unique_docs = []\n","\n","    for doc in all_docs:\n","        # Use first 100 chars as a simple deduplication key\n","        content_key = doc.page_content[:100]\n","        if content_key not in seen_contents:\n","            unique_docs.append(doc)\n","            seen_contents.add(content_key)\n","\n","    return unique_docs\n","\n","# Create specialized retrievers\n","def create_specialized_retrievers():\n","    \"\"\"Create specialized retrievers for different types of queries\"\"\"\n","\n","    # Language-specific retrievers\n","    python_retriever = vectorstore.as_retriever(\n","        search_kwargs={\"k\": 2, \"filter\": {\"language\": \"python\"}}\n","    )\n","\n","    js_retriever = vectorstore.as_retriever(\n","        search_kwargs={\"k\": 2, \"filter\": {\"language\": \"javascript\"}}\n","    )\n","\n","    # Category-specific retrievers\n","    function_retriever = vectorstore.as_retriever(\n","        search_kwargs={\"k\": 2, \"filter\": {\"category\": \"functions\"}}\n","    )\n","\n","    data_structures_retriever = vectorstore.as_retriever(\n","        search_kwargs={\"k\": 2, \"filter\": {\"category\": \"data_structures\"}}\n","    )\n","\n","    # Generic retriever with higher k for broader queries\n","    generic_retriever = vectorstore.as_retriever(\n","        search_kwargs={\"k\": 3}\n","    )\n","\n","    return {\n","        \"python\": python_retriever,\n","        \"javascript\": js_retriever,\n","        \"functions\": function_retriever,\n","        \"data_structures\": data_structures_retriever,\n","        \"generic\": generic_retriever\n","    }\n","\n","# Simple query router\n","def route_query(query, retrievers):\n","    \"\"\"Route a query to the appropriate specialized retriever\"\"\"\n","    query_lower = query.lower()\n","\n","    if \"python\" in query_lower:\n","        return \"python\", retrievers[\"python\"]\n","    elif \"javascript\" in query_lower or \"js\" in query_lower:\n","        return \"javascript\", retrievers[\"javascript\"]\n","    elif \"function\" in query_lower or \"method\" in query_lower:\n","        return \"functions\", retrievers[\"functions\"]\n","    elif \"list\" in query_lower or \"array\" in query_lower or \"data structure\" in query_lower:\n","        return \"data_structures\", retrievers[\"data_structures\"]\n","    else:\n","        return \"generic\", retrievers[\"generic\"]\n","\n","# Test multi-query retrieval\n","print(\"\\nüîÑ Testing multi-query retrieval:\")\n","test_query = \"How do Python lists work?\"\n","results = retrieve_with_variations(test_query, retriever, n_variations=2)\n","print(f\"Retrieved {len(results)} unique documents\\n\")\n","\n","# Test specialized retriever routing\n","print(\"\\nüö¶ Testing specialized retriever routing:\")\n","specialized_retrievers = create_specialized_retrievers()\n","\n","test_queries = [\n","    \"How do Python lists work?\",\n","    \"JavaScript function syntax\",\n","    \"Best data structures for searching\"\n","]\n","\n","for query in test_queries:\n","    retriever_name, specialized_retriever = route_query(query, specialized_retrievers)\n","    print(f\"Query: {query}\")\n","    print(f\"Routed to: {retriever_name} retriever\\n\")"],"metadata":{"id":"DeukbTy5K_OD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**10.5.4 Advanced Filtering and Query Construction**"],"metadata":{"id":"QwJqn4iKLNBx"}},{"cell_type":"code","source":["# Create a schema for filter specifications\n","class FilterSpec(BaseModel):\n","    field: str = Field(description=\"The metadata field to filter on\")\n","    value: Any = Field(description=\"The value to filter for\")\n","    operator: str = Field(description=\"The operation to perform (equals, contains, greater_than, less_than, in_list)\")\n","\n","class FilterGroup(BaseModel):\n","    filters: List[FilterSpec] = Field(description=\"List of filter specifications\")\n","    logic: str = Field(description=\"Logic to combine filters (AND, OR)\")\n","\n","# Function to generate filters based on natural language query\n","def generate_dynamic_filters(query, available_metadata_fields):\n","    \"\"\"Generate filter specifications based on a natural language query\"\"\"\n","\n","    # Create a prompt that explains available metadata fields\n","    fields_description = \"\\n\".join([f\"- {field}\" for field in available_metadata_fields])\n","\n","    prompt = f\"\"\"Based on this query, create filter specifications for a document retrieval system.\n","\n","Available metadata fields:\n","{fields_description}\n","\n","Query: {query}\n","\n","Generate JSON for filters that would help retrieve the most relevant documents.\n","Use this format:\n","{{\n","  \"filters\": [\n","    {{\n","      \"field\": \"field_name\",\n","      \"value\": \"value to match\",\n","      \"operator\": \"equals\"  # Can be: equals, contains, greater_than, less_than, in_list\n","    }}\n","  ],\n","  \"logic\": \"AND\"  # Can be: AND, OR\n","}}\n","\n","If no filters are needed, return an empty filters list.\n","\"\"\"\n","\n","    # Create parser for the filter specification\n","    parser = PydanticOutputParser(pydantic_object=FilterGroup)\n","\n","    try:\n","        # Generate filter specification\n","        response = llm.invoke(prompt).content\n","\n","        # Extract JSON from response (in case the model includes explanation text)\n","        import re\n","        json_match = re.search(r'({.*})', response.replace('\\n', ' '), re.DOTALL)\n","        if json_match:\n","            response_json = json_match.group(1)\n","            # Parse the filter specification\n","            filter_group = parser.parse(response_json)\n","            return filter_group\n","        else:\n","            # Fallback: return empty filter group\n","            return FilterGroup(filters=[], logic=\"AND\")\n","\n","    except Exception as e:\n","        print(f\"Error generating filters: {str(e)}\")\n","        # Return empty filter group as fallback\n","        return FilterGroup(filters=[], logic=\"AND\")\n","\n","# Convert filter specifications to retriever search_kwargs\n","def convert_filters_to_search_kwargs(filter_group):\n","    \"\"\"Convert a FilterGroup to search_kwargs for a retriever\"\"\"\n","\n","    # For Chroma, we'll use the \"where\" filter format\n","    filter_dict = {}\n","\n","    # If no filters, return empty dict\n","    if not filter_group.filters:\n","        return {}\n","\n","    # Process each filter\n","    for f in filter_group.filters:\n","        if f.operator == \"equals\":\n","            filter_dict[f.field] = f.value\n","        elif f.operator == \"contains\":\n","            # This depends on your vector store's capabilities\n","            # Some might support contains with special syntax\n","            filter_dict[f.field] = {\"$in\": [f.value]}\n","        elif f.operator == \"greater_than\":\n","            filter_dict[f.field] = {\"$gt\": f.value}\n","        elif f.operator == \"less_than\":\n","            filter_dict[f.field] = {\"$lt\": f.value}\n","        elif f.operator == \"in_list\":\n","            filter_dict[f.field] = {\"$in\": f.value if isinstance(f.value, list) else [f.value]}\n","\n","    # Return as search_kwargs\n","    return {\"filter\": filter_dict}\n","\n","# Test dynamic filter generation\n","print(\"\\nüîç Testing dynamic filter generation:\")\n","available_metadata_fields = [\"language\", \"category\", \"source\"]\n","\n","test_queries = [\n","    \"Tell me about Python functions\",\n","    \"How do arrays work in JavaScript?\"\n","]\n","\n","for query in test_queries:\n","    filters = generate_dynamic_filters(query, available_metadata_fields)\n","    search_kwargs = convert_filters_to_search_kwargs(filters)\n","\n","    print(f\"Query: {query}\")\n","    print(f\"Generated Filters: {json.dumps(filters.dict(), indent=2)}\")\n","    print(f\"Search kwargs: {search_kwargs}\\n\")"],"metadata":{"id":"QXkMqOZqLNIu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**10.5.5 Managing High Cardinality Variables**"],"metadata":{"id":"UlDWLIQBLYT6"}},{"cell_type":"code","source":["# Simulate a high-cardinality scenario with programming languages\n","def create_high_cardinality_kb():\n","    \"\"\"Create a knowledge base with high cardinality in language field\"\"\"\n","\n","    languages = [\n","        \"Python\", \"JavaScript\", \"Java\", \"C++\", \"C#\", \"Ruby\", \"Go\", \"Swift\",\n","        \"Kotlin\", \"Rust\", \"PHP\", \"TypeScript\", \"Scala\", \"Perl\", \"Haskell\"\n","    ]\n","\n","    docs = []\n","    for lang in languages:\n","        doc = Document(\n","            page_content=f\"{lang} is a programming language used for various types of software development.\",\n","            metadata={\"language\": lang.lower(), \"type\": \"language_overview\"}\n","        )\n","        docs.append(doc)\n","\n","        # Add 1-2 more documents for some languages\n","        if random.random() < 0.3:\n","            doc = Document(\n","                page_content=f\"{lang} is known for its {random.choice(['performance', 'simplicity', 'flexibility', 'strong type system'])}.\",\n","                metadata={\"language\": lang.lower(), \"type\": \"language_feature\"}\n","            )\n","            docs.append(doc)\n","\n","    # Create embeddings and vectorstore\n","    embeddings = OpenAIEmbeddings()\n","    high_cardinality_store = Chroma.from_documents(documents=docs, embedding=embeddings)\n","    return high_cardinality_store, languages, embeddings\n","\n","high_cardinality_store, languages, hc_embeddings = create_high_cardinality_kb()\n","print(f\"üìö Created high-cardinality knowledge base with {len(languages)} languages\")\n","\n","# Approach 1: LLM-based category selection\n","def expand_query_with_categories(query, category_field, all_categories, llm):\n","    \"\"\"Expand a query to include likely relevant categories from high-cardinality fields\"\"\"\n","\n","    # Create a prompt that includes available categories\n","    categories_str = \", \".join(all_categories[:20])  # Limit to 20 for prompt size\n","    if len(all_categories) > 20:\n","        categories_str += f\", and {len(all_categories) - 20} more\"\n","\n","    prompt = f\"\"\"Based on this query, identify which categories from the \"{category_field}\" field\n","would be most relevant. These will be used to filter search results.\n","\n","Available categories include: {categories_str}\n","\n","Query: {query}\n","\n","List the 1-3 most relevant categories, separated by commas. Only include categories that are\n","definitely relevant, and stick to the exact category names provided.\n","\"\"\"\n","\n","    try:\n","        response = llm.invoke(prompt).content\n","\n","        # Extract categories from response\n","        # Use a comma-separated list parser\n","        parser = CommaSeparatedListOutputParser()\n","        categories = parser.parse(response)\n","\n","        # Validate against actual categories\n","        valid_categories = [c.lower() for c in all_categories]\n","        validated = [c.lower() for c in categories if c.lower() in valid_categories]\n","\n","        return validated\n","\n","    except Exception as e:\n","        print(f\"Error in query expansion: {str(e)}\")\n","        return []\n","\n","# Test LLM-based category selection\n","print(\"\\nü§ñ Testing LLM-based category selection for high-cardinality fields:\")\n","test_queries = [\n","    \"I need help with web development\",\n","    \"What's good for data analysis?\",\n","    \"Mobile app development languages\"\n","]\n","\n","for query in test_queries:\n","    selected_langs = expand_query_with_categories(query, \"language\", languages, llm)\n","\n","    print(f\"Query: {query}\")\n","    print(f\"Selected languages: {', '.join(selected_langs)}\\n\")\n","\n","print(\"\\n‚úÖ Advanced Query Analysis and Optimization notebook complete!\")"],"metadata":{"id":"MefUG-KcLYbt"},"execution_count":null,"outputs":[]}]}