{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPxqltStj56rgk/ktGwSp3i"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# First, install required packages\n","!pip install fastapi uvicorn beautifulsoup4 requests playwright\n","\n","# Install Playwright browsers\n","!playwright install\n","\n","# Import necessary libraries\n","from fastapi import FastAPI\n","import uvicorn\n","import json\n","from threading import Thread\n","import requests\n","from bs4 import BeautifulSoup\n","from playwright.async_api import async_playwright\n","import asyncio\n","import nest_asyncio\n","\n","# Enable nested asyncio for Colab\n","nest_asyncio.apply()\n","\n","print(\"Web processing environment setup complete!\")\n","\n","# Create a simple FastAPI server with dynamic content\n","app = FastAPI()\n","\n","@app.get(\"/\")\n","async def read_root():\n","    return {\n","        \"html\": \"\"\"\n","        <!DOCTYPE html>\n","        <html>\n","        <body>\n","            <div id=\"content\">Loading...</div>\n","            <script>\n","                setTimeout(() => {\n","                    document.getElementById('content').innerText = 'Loaded Content';\n","                }, 2000);\n","            </script>\n","        </body>\n","        </html>\n","        \"\"\"\n","    }\n","\n","# Start server in a separate thread\n","def run_server():\n","    uvicorn.run(app, host=\"127.0.0.1\", port=8000)\n","\n","server_thread = Thread(target=run_server, daemon=True)\n","server_thread.start()\n","\n","class DynamicWebLoader:\n","    \"\"\"\n","    Handles web pages that load content dynamically through JavaScript.\n","    \"\"\"\n","    def __init__(self, url: str, wait_time: int = 5):\n","        self.url = url\n","        self.wait_time = wait_time\n","\n","    async def load_dynamic_content(self) -> str:\n","        \"\"\"\n","        Load a webpage and wait for dynamic content to render.\n","        Uses Playwright to handle JavaScript execution.\n","        \"\"\"\n","        async with async_playwright() as p:\n","            browser = await p.chromium.launch()\n","            page = await browser.new_page()\n","\n","            # Load the page and wait for dynamic content\n","            await page.goto(self.url)\n","            await page.wait_for_timeout(self.wait_time * 1000)\n","\n","            # Extract the rendered content\n","            content = await page.content()\n","            await browser.close()\n","\n","            return content\n","\n","# Test function using asyncio\n","async def test_dynamic_loader():\n","    \"\"\"Test the dynamic content loader\"\"\"\n","    loader = DynamicWebLoader(\"http://127.0.0.1:8000\")\n","    content = await loader.load_dynamic_content()\n","    print(\"Dynamic content loaded:\", 'Loaded Content' in content)\n","\n","# Run the test\n","await test_dynamic_loader()"],"metadata":{"id":"2PK19sD2rSxn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class StructuredHTMLProcessor:\n","    \"\"\"\n","    Processes HTML documents while preserving their semantic structure.\n","    \"\"\"\n","    def __init__(self, html_content: str):\n","        self.soup = BeautifulSoup(html_content, 'html.parser')\n","\n","    def extract_main_article(self) -> dict:\n","        \"\"\"Extract the main content from article tags or main content area.\"\"\"\n","        article = self.soup.find('article') or self.soup.find('main')\n","        if article:\n","            return {\n","                'content': article.get_text(strip=True),\n","                'has_article_tag': bool(self.soup.find('article')),\n","                'word_count': len(article.get_text().split())\n","            }\n","        return {}\n","\n","    def extract_heading_hierarchy(self) -> list:\n","        \"\"\"Extract headings while preserving their hierarchical structure.\"\"\"\n","        headings = []\n","        for level in range(1, 7):\n","            for heading in self.soup.find_all(f'h{level}'):\n","                headings.append({\n","                    'level': level,\n","                    'text': heading.get_text(strip=True),\n","                    'id': heading.get('id', ''),\n","                    'has_links': bool(heading.find_all('a'))\n","                })\n","        return headings\n","\n","    def extract_lists(self) -> dict:\n","        \"\"\"Extract ordered and unordered lists.\"\"\"\n","        lists = {\n","            'ordered': [],\n","            'unordered': [],\n","            'definition': []\n","        }\n","\n","        # Process ordered lists\n","        for ol in self.soup.find_all('ol'):\n","            lists['ordered'].append([\n","                item.get_text(strip=True) for item in ol.find_all('li')\n","            ])\n","\n","        # Process unordered lists\n","        for ul in self.soup.find_all('ul'):\n","            lists['unordered'].append([\n","                item.get_text(strip=True) for item in ul.find_all('li')\n","            ])\n","\n","        # Process definition lists\n","        for dl in self.soup.find_all('dl'):\n","            defs = []\n","            for dt, dd in zip(dl.find_all('dt'), dl.find_all('dd')):\n","                defs.append({\n","                    'term': dt.get_text(strip=True),\n","                    'definition': dd.get_text(strip=True)\n","                })\n","            lists['definition'].append(defs)\n","\n","        return lists\n","\n","    def extract_metadata(self) -> dict:\n","        \"\"\"Extract metadata from meta tags and other sources.\"\"\"\n","        metadata = {\n","            'title': self.soup.title.string if self.soup.title else '',\n","            'meta': {},\n","            'links': []\n","        }\n","\n","        # Extract meta tags\n","        for meta in self.soup.find_all('meta'):\n","            name = meta.get('name', meta.get('property', ''))\n","            if name:\n","                metadata['meta'][name] = meta.get('content', '')\n","\n","        # Extract important links\n","        for link in self.soup.find_all('a'):\n","            metadata['links'].append({\n","                'text': link.get_text(strip=True),\n","                'href': link.get('href', ''),\n","                'title': link.get('title', '')\n","            })\n","\n","        return metadata\n","\n","# Let's test our HTML processor with a sample document\n","def test_html_processor():\n","    \"\"\"Test the structured HTML processor with a sample document\"\"\"\n","\n","    sample_html = \"\"\"\n","    <!DOCTYPE html>\n","    <html>\n","    <head>\n","        <title>Sample Document</title>\n","        <meta name=\"description\" content=\"A test document\">\n","        <meta name=\"keywords\" content=\"test, sample, document\">\n","    </head>\n","    <body>\n","        <article>\n","            <h1>Main Title</h1>\n","            <p>This is the introduction.</p>\n","\n","            <h2>First Section</h2>\n","            <ul>\n","                <li>First point</li>\n","                <li>Second point</li>\n","            </ul>\n","\n","            <h2>Second Section</h2>\n","            <ol>\n","                <li>Step one</li>\n","                <li>Step two</li>\n","            </ol>\n","\n","            <dl>\n","                <dt>Term 1</dt>\n","                <dd>Definition 1</dd>\n","                <dt>Term 2</dt>\n","                <dd>Definition 2</dd>\n","            </dl>\n","        </article>\n","    </body>\n","    </html>\n","    \"\"\"\n","\n","    # Process the HTML\n","    processor = StructuredHTMLProcessor(sample_html)\n","\n","    # Extract and display different components\n","    print(\"Article Content:\")\n","    print(json.dumps(processor.extract_main_article(), indent=2))\n","\n","    print(\"\\nHeading Hierarchy:\")\n","    print(json.dumps(processor.extract_heading_hierarchy(), indent=2))\n","\n","    print(\"\\nLists:\")\n","    print(json.dumps(processor.extract_lists(), indent=2))\n","\n","    print(\"\\nMetadata:\")\n","    print(json.dumps(processor.extract_metadata(), indent=2))\n","\n","# Run the test\n","test_html_processor()"],"metadata":{"id":"f9hPGwLGs-f8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from typing import List, Dict, Any\n","import json\n","from bs4 import BeautifulSoup\n","\n","class WebEmbeddedJSONProcessor:\n","    \"\"\"\n","    Handles JSON data embedded in or loaded by web pages.\n","    \"\"\"\n","    def __init__(self, html_content: str):\n","        self.soup = BeautifulSoup(html_content, 'html.parser')\n","\n","    def extract_json_ld(self) -> List[dict]:\n","        \"\"\"Extract JSON-LD metadata from HTML content.\"\"\"\n","        json_ld_tags = self.soup.find_all('script', type='application/ld+json')\n","        results = []\n","\n","        for tag in json_ld_tags:\n","            try:\n","                data = json.loads(tag.string)\n","                results.append(data)\n","            except json.JSONDecodeError:\n","                continue\n","\n","        return results\n","\n","    def process_api_response(self, response_text: str) -> dict:\n","        \"\"\"\n","        Process JSON from API responses.\n","        Handles JSON that's dynamically loaded into the page.\n","        \"\"\"\n","        try:\n","            data = json.loads(response_text)\n","            return {\n","                'data': self.normalize_api_data(data),\n","                'metadata': self.extract_api_metadata(data)\n","            }\n","        except json.JSONDecodeError:\n","            return {'error': 'Invalid JSON in API response'}\n","\n","    def normalize_api_data(self, data: Any) -> Any:\n","        \"\"\"Normalize API response data for consistent processing.\"\"\"\n","        if isinstance(data, dict):\n","            return {\n","                key: self.normalize_api_data(value)\n","                for key, value in data.items()\n","            }\n","        elif isinstance(data, list):\n","            return [self.normalize_api_data(item) for item in data]\n","        return data\n","\n","    def extract_api_metadata(self, data: dict) -> dict:\n","        \"\"\"Extract metadata from API response.\"\"\"\n","        metadata = {}\n","        if isinstance(data, dict):\n","            # Extract common metadata fields\n","            metadata = {\n","                'total_items': data.get('total'),\n","                'page': data.get('page'),\n","                'has_more': data.get('has_more', False),\n","                'timestamp': data.get('timestamp')\n","            }\n","        return metadata\n","\n","def test_json_processor():\n","    \"\"\"Test processing different types of web-embedded JSON\"\"\"\n","\n","    # Create a test page with embedded JSON-LD\n","    test_html = \"\"\"\n","    <html>\n","    <head>\n","        <script type=\"application/ld+json\">\n","        {\n","            \"@context\": \"https://schema.org\",\n","            \"@type\": \"Article\",\n","            \"headline\": \"Understanding RAG Systems\",\n","            \"author\": {\n","                \"@type\": \"Person\",\n","                \"name\": \"John Doe\"\n","            }\n","        }\n","        </script>\n","    </head>\n","    <body>\n","        <div id=\"content\">Main content here</div>\n","    </body>\n","    </html>\n","    \"\"\"\n","\n","    # Test JSON-LD extraction\n","    processor = WebEmbeddedJSONProcessor(test_html)\n","    json_ld = processor.extract_json_ld()\n","\n","    print(\"Extracted JSON-LD:\")\n","    print(json.dumps(json_ld, indent=2))\n","\n","    # Test API response processing\n","    api_response = {\n","        \"products\": [\n","            {\"id\": 1, \"name\": \"Product A\", \"price\": 29.99},\n","            {\"id\": 2, \"name\": \"Product B\", \"price\": 39.99}\n","        ],\n","        \"metadata\": {\n","            \"total\": 2,\n","            \"page\": 1\n","        }\n","    }\n","\n","    normalized_data = processor.process_api_response(json.dumps(api_response))\n","    print(\"\\nProcessed API Response:\")\n","    print(json.dumps(normalized_data, indent=2))\n","\n","# Run the test\n","test_json_processor()"],"metadata":{"id":"02KK0ZxmvZkG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Bringing It All Together**"],"metadata":{"id":"9eCXZTF5xWuy"}},{"cell_type":"code","source":["class ComprehensiveWebProcessor:\n","    \"\"\"\n","    A unified processor that handles dynamic content, HTML structure,\n","    and embedded JSON in web pages.\n","    \"\"\"\n","    def __init__(self, url: str, wait_time: int = 5):\n","        self.url = url\n","        self.wait_time = wait_time\n","        self.raw_html = None\n","        self.processed_content = {}\n","\n","    async def process_page(self) -> dict:\n","        \"\"\"\n","        Process a webpage combining all our processing capabilities.\n","        Returns a complete analysis of the page content.\n","        \"\"\"\n","        # 1. Load dynamic content\n","        dynamic_loader = DynamicWebLoader(self.url)\n","        self.raw_html = await dynamic_loader.load_dynamic_content()\n","\n","        # 2. Process HTML structure\n","        html_processor = StructuredHTMLProcessor(self.raw_html)\n","        html_structure = {\n","            'main_content': html_processor.extract_main_article(),\n","            'headings': html_processor.extract_heading_hierarchy(),\n","            'lists': html_processor.extract_lists(),\n","            'metadata': html_processor.extract_metadata()\n","        }\n","\n","        # 3. Handle embedded JSON\n","        json_processor = WebEmbeddedJSONProcessor(self.raw_html)\n","        json_ld = json_processor.extract_json_ld()\n","\n","        # 4. Combine all information\n","        self.processed_content = {\n","            'structural_content': html_structure,\n","            'embedded_json': json_ld,\n","            'metadata': {\n","                'url': self.url,\n","                'processing_time': self.wait_time,\n","                'has_dynamic_content': bool(html_structure.get('main_content'))\n","            }\n","        }\n","\n","        return self.processed_content"],"metadata":{"id":"thlfIEVf_fdG","executionInfo":{"status":"ok","timestamp":1739126422110,"user_tz":-330,"elapsed":13,"user":{"displayName":"ranajoy bose","userId":"06328792273740913169"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["async def test_comprehensive_processor():\n","    \"\"\"Test the comprehensive web content processor\"\"\"\n","\n","    # Start our test server with a complex page\n","    app = FastAPI()\n","\n","    @app.get(\"/\")\n","    async def read_root():\n","        return {\n","            \"html\": \"\"\"\n","            <!DOCTYPE html>\n","            <html>\n","            <head>\n","                <title>Test Complex Page</title>\n","                <script type=\"application/ld+json\">\n","                {\n","                    \"@context\": \"https://schema.org\",\n","                    \"@type\": \"Article\",\n","                    \"headline\": \"Test Article\"\n","                }\n","                </script>\n","            </head>\n","            <body>\n","                <article>\n","                    <h1>Main Content</h1>\n","                    <p>Static content here</p>\n","                    <div id=\"dynamic-content\">Loading...</div>\n","                    <script>\n","                        setTimeout(() => {\n","                            document.getElementById('dynamic-content').innerText =\n","                                'Dynamically Loaded Content';\n","                        }, 1000);\n","                    </script>\n","                    <ul>\n","                        <li>First item</li>\n","                        <li>Second item</li>\n","                    </ul>\n","                </article>\n","            </body>\n","            </html>\n","            \"\"\"\n","        }\n","\n","    # Start server in thread\n","    server_thread = Thread(target=lambda: uvicorn.run(app, host=\"127.0.0.1\", port=8000))\n","    server_thread.daemon = True\n","    server_thread.start()\n","\n","    # Allow server to start\n","    await asyncio.sleep(1)\n","\n","    # Test the processor\n","    processor = ComprehensiveWebProcessor(\"http://127.0.0.1:8000\")\n","    content = await processor.process_page()\n","\n","    print(\"Comprehensive Processing Results:\")\n","    print(\"\\n1. Structural Content:\")\n","    print(json.dumps(content['structural_content'], indent=2))\n","\n","    print(\"\\n2. Embedded JSON:\")\n","    print(json.dumps(content['embedded_json'], indent=2))\n","\n","    print(\"\\n3. Metadata:\")\n","    print(json.dumps(content['metadata'], indent=2))\n","\n","# Run the comprehensive test\n","await test_comprehensive_processor()"],"metadata":{"id":"mTxy44uzAQbf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Best Practices and Common Challenges**"],"metadata":{"id":"BER-HuAOCyvv"}},{"cell_type":"code","source":["import time\n","import asyncio\n","from typing import Dict, Any\n","\n","class DynamicContentBestPractices:\n","    \"\"\"Demonstrate best practices for dynamic content timing\"\"\"\n","\n","    def __init__(self, url: str):\n","        self.url = url\n","\n","    async def wait_for_content(self, selector: str, timeout: int = 30) -> bool:\n","        \"\"\"\n","        Wait for specific content to appear using smart timing.\n","        Returns True if content appears within timeout.\n","        \"\"\"\n","        async with async_playwright() as p:\n","            browser = await p.chromium.launch()\n","            page = await browser.new_page()\n","\n","            try:\n","                # Navigate with timeout\n","                await page.goto(self.url, timeout=timeout * 1000)\n","\n","                # Wait for specific content\n","                await page.wait_for_selector(selector, timeout=timeout * 1000)\n","                return True\n","\n","            except Exception as e:\n","                print(f\"Timeout waiting for content: {str(e)}\")\n","                return False\n","\n","            finally:\n","                await browser.close()"],"metadata":{"id":"0DJmlh4pC3V0","executionInfo":{"status":"ok","timestamp":1739127184196,"user_tz":-330,"elapsed":15,"user":{"displayName":"ranajoy bose","userId":"06328792273740913169"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["class WebContentErrorHandler:\n","    \"\"\"Handle common web content processing errors\"\"\"\n","\n","    @staticmethod\n","    async def process_with_retry(processor: ComprehensiveWebProcessor, max_retries: int = 3):\n","        \"\"\"Process content with automatic retry on failure\"\"\"\n","        for attempt in range(max_retries):\n","            try:\n","                return await processor.process_page()\n","            except Exception as e:\n","                if attempt == max_retries - 1:\n","                    raise e\n","                print(f\"Attempt {attempt + 1} failed, retrying...\")\n","                await asyncio.sleep(2 ** attempt)  # Exponential backoff"],"metadata":{"id":"8LlAZxLqC938","executionInfo":{"status":"ok","timestamp":1739127187502,"user_tz":-330,"elapsed":11,"user":{"displayName":"ranajoy bose","userId":"06328792273740913169"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["class ContentValidator:\n","    \"\"\"Validate processed web content\"\"\"\n","\n","    @staticmethod\n","    def validate_processed_content(content: dict) -> dict:\n","        \"\"\"\n","        Validate and report on processed content quality.\n","        Returns validation results.\n","        \"\"\"\n","        validation = {\n","            'is_valid': True,\n","            'issues': [],\n","            'warnings': []\n","        }\n","\n","        # Check structural content\n","        if not content.get('structural_content', {}).get('main_content'):\n","            validation['warnings'].append('No main content found')\n","\n","        # Check JSON-LD\n","        if not content.get('embedded_json'):\n","            validation['warnings'].append('No JSON-LD data found')\n","\n","        # Check metadata\n","        if not content.get('metadata', {}).get('url'):\n","            validation['issues'].append('Missing URL in metadata')\n","            validation['is_valid'] = False\n","\n","        return validation"],"metadata":{"id":"TaIRtJlGDBKa","executionInfo":{"status":"ok","timestamp":1739127189669,"user_tz":-330,"elapsed":19,"user":{"displayName":"ranajoy bose","userId":"06328792273740913169"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["class PerformanceMonitor:\n","    \"\"\"Monitor web content processing performance\"\"\"\n","\n","    def __init__(self):\n","        self.metrics = []\n","\n","    async def measure_processing_time(self, processor: ComprehensiveWebProcessor) -> dict:\n","        \"\"\"Measure processing time for different components\"\"\"\n","        metrics = {}\n","\n","        start_time = time.time()\n","        content = await processor.process_page()\n","        total_time = time.time() - start_time\n","\n","        metrics['total_processing_time'] = total_time\n","        metrics['content_size'] = len(str(content))\n","        metrics['timestamp'] = time.time()\n","\n","        self.metrics.append(metrics)\n","        return metrics"],"metadata":{"id":"CQNOpYqrDECi","executionInfo":{"status":"ok","timestamp":1739127192503,"user_tz":-330,"elapsed":15,"user":{"displayName":"ranajoy bose","userId":"06328792273740913169"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["async def demonstrate_best_practices():\n","    \"\"\"Show how to implement best practices\"\"\"\n","\n","    # Setup test environment\n","    url = \"http://127.0.0.1:8000\"\n","\n","    # 1. Test dynamic content timing\n","    timing = DynamicContentBestPractices(url)\n","    content_loaded = await timing.wait_for_content(\"#dynamic-content\")\n","    print(f\"Dynamic content loaded: {content_loaded}\")\n","\n","    # 2. Test error handling\n","    processor = ComprehensiveWebProcessor(url)\n","    error_handler = WebContentErrorHandler()\n","    content = await error_handler.process_with_retry(processor)\n","\n","    # 3. Validate content\n","    validator = ContentValidator()\n","    validation_results = validator.validate_processed_content(content)\n","    print(\"\\nValidation Results:\")\n","    print(json.dumps(validation_results, indent=2))\n","\n","    # 4. Monitor performance\n","    monitor = PerformanceMonitor()\n","    metrics = await monitor.measure_processing_time(processor)\n","    print(\"\\nPerformance Metrics:\")\n","    print(json.dumps(metrics, indent=2))\n","\n","# Run the demonstration\n","await demonstrate_best_practices()"],"metadata":{"id":"vLfDwCD-DG3A"},"execution_count":null,"outputs":[]}]}